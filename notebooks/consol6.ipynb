{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "869c9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1812, 51)\n",
      "Test set shape: (453, 45)\n",
      "'W' column in train dataset: True\n",
      "'W' column in test dataset: False\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Build robust path to data folder (notebooks and data are siblings)\n",
    "DATA_DIR = Path.cwd().parent / 'data'\n",
    "SUB_DIR = Path.cwd().parent / 'submissions'\n",
    "train_path = DATA_DIR / 'train.csv'\n",
    "test_path = DATA_DIR / 'test.csv'\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)  # This is for final predictions (no 'W' column)\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"'W' column in train dataset: {'W' in train_df.columns}\")\n",
    "print(f\"'W' column in test dataset: {'W' in test_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d476af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created derived features: R_per_game, RA_per_game\n",
      "Train - R_per_game range: 2.409 to 6.884\n",
      "Train - RA_per_game range: 2.458 to 7.686\n",
      "Test - R_per_game range: 2.783 to 6.896\n",
      "Test - RA_per_game range: 2.867 to 6.865\n",
      "\n",
      "Created derived feature: Expected_Wins\n",
      "Train - Expected_Wins range: 35.860 to 119.963\n",
      "Test - Expected_Wins range: 40.352 to 107.111\n",
      "\n",
      "Created derived feature: Times_On_Base\n",
      "Train - Times_On_Base range: 1367.000 to 2415.000\n",
      "Test - Times_On_Base range: 1453.000 to 2327.000\n",
      "\n",
      "Created derived feature: BB_Rate\n",
      "Train - BB_Rate range: 0.051 to 0.136\n",
      "Test - BB_Rate range: 0.052 to 0.123\n",
      "\n",
      "Created derived feature: HR_Rate\n",
      "Train - HR_Rate range: 0.001 to 0.047\n",
      "Test - HR_Rate range: 0.001 to 0.045\n",
      "\n",
      "Created derived feature: OBP\n",
      "Train - OBP range: 0.262 to 0.382\n",
      "Test - OBP range: 0.267 to 0.382\n",
      "\n",
      "Created derived feature: SLG\n",
      "Train - SLG range: 0.274 to 0.491\n",
      "Test - SLG range: 0.261 to 0.488\n",
      "\n",
      "Created derived feature: OPS\n",
      "Train - OPS range: 0.539 to 0.870\n",
      "Test - OPS range: 0.530 to 0.870\n",
      "\n",
      "Created derived feature: Times_On_Base_Allowed\n",
      "Train - Times_On_Base_Allowed range: 1441.000 to 2536.000\n",
      "Test - Times_On_Base_Allowed range: 1454.000 to 2421.000\n",
      "\n",
      "Created derived feature: WHIP\n",
      "Train - WHIP range: 1.025 to 1.848\n",
      "Test - WHIP range: 1.028 to 1.776\n",
      "\n",
      "Created derived feature: K_per_9\n",
      "Train - K_per_9 range: 2.102 to 9.353\n",
      "Test - K_per_9 range: 2.064 to 8.704\n",
      "\n",
      "Created derived feature: HR_per_9\n",
      "Train - HR_per_9 range: 0.032 to 1.610\n",
      "Test - HR_per_9 range: 0.040 to 1.429\n",
      "\n",
      "Created derived feature: REI\n",
      "Train - REI range: 1.475 to 2.545\n",
      "Test - REI range: 1.554 to 2.402\n",
      "\n",
      "Created derived feature: PEI\n",
      "Train - PEI range: 0.975 to 28.452\n",
      "Test - PEI range: 1.215 to 27.720\n",
      "\n",
      "Created derived feature: Era_Adjusted_OBP\n",
      "Train - Era_Adjusted_OBP range: 0.246 to 0.434\n",
      "Test - Era_Adjusted_OBP range: 0.254 to 0.405\n",
      "\n",
      "Created derived feature: Era_Adjusted_SLG\n",
      "Train - Era_Adjusted_SLG range: 0.289 to 0.501\n",
      "Test - Era_Adjusted_SLG range: 0.298 to 0.482\n",
      "\n",
      "Created derived feature: Era_Adjusted_OPS\n",
      "Train - Era_Adjusted_OPS range: 0.536 to 0.910\n",
      "Test - Era_Adjusted_OPS range: 0.564 to 0.850\n",
      "\n",
      "Created derived feature: Era_Adjusted_WHIP\n",
      "Train - Era_Adjusted_WHIP range: 1.084 to 1.882\n",
      "Test - Era_Adjusted_WHIP range: 1.127 to 1.707\n",
      "\n",
      "Created derived feature: Era_Adjusted_K_per_9\n",
      "Train - Era_Adjusted_K_per_9 range: 1.847 to 9.626\n",
      "Test - Era_Adjusted_K_per_9 range: 1.795 to 8.963\n",
      "\n",
      "Created derived feature: Era_Adjusted_HR_per_9\n",
      "Train - Era_Adjusted_HR_per_9 range: 0.040 to 1.584\n",
      "Test - Era_Adjusted_HR_per_9 range: 0.043 to 1.347\n",
      "\n",
      "Created derived feature: Era_Adjusted_BB_Rate\n",
      "Train - Era_Adjusted_BB_Rate range: 0.049 to 0.136\n",
      "Test - Era_Adjusted_BB_Rate range: 0.046 to 0.133\n",
      "\n",
      "Created derived feature: Era_Adjusted_HR_Rate\n",
      "Train - Era_Adjusted_HR_Rate range: 0.001 to 0.047\n",
      "Test - Era_Adjusted_HR_Rate range: 0.001 to 0.043\n"
     ]
    }
   ],
   "source": [
    "# Create derived features for both train and test sets\n",
    "\n",
    "# R_per_game: Runs per game\n",
    "# RA_per_game: Runs allowed per game\n",
    "train_df['R_per_game'] = train_df['R'] / train_df['G']\n",
    "train_df['RA_per_game'] = train_df['RA'] / train_df['G']\n",
    "test_df['R_per_game'] = test_df['R'] / test_df['G']\n",
    "test_df['RA_per_game'] = test_df['RA'] / test_df['G']\n",
    "\n",
    "print(f\"\\nCreated derived features: R_per_game, RA_per_game\")\n",
    "print(f\"Train - R_per_game range: {train_df['R_per_game'].min():.3f} to {train_df['R_per_game'].max():.3f}\")\n",
    "print(f\"Train - RA_per_game range: {train_df['RA_per_game'].min():.3f} to {train_df['RA_per_game'].max():.3f}\")\n",
    "print(f\"Test - R_per_game range: {test_df['R_per_game'].min():.3f} to {test_df['R_per_game'].max():.3f}\")\n",
    "print(f\"Test - RA_per_game range: {test_df['RA_per_game'].min():.3f} to {test_df['RA_per_game'].max():.3f}\")\n",
    "\n",
    "# Expected Wins of Season = G × (R²) / (R² + RA²)\n",
    "train_df['Expected_Wins'] = train_df['G'] * (train_df['R_per_game'] ** 2) / ((train_df['R_per_game'] ** 2) + (train_df['RA_per_game'] ** 2))\n",
    "test_df['Expected_Wins'] = test_df['G'] * (test_df['R_per_game'] ** 2) / ((test_df['R_per_game'] ** 2) + (test_df['RA_per_game'] ** 2))\n",
    "# train_df['Expected_Wins'] = train_df['G'] * (train_df['R'] ** 2) / ((train_df['R'] ** 2) + (train_df['RA'] ** 2))\n",
    "# test_df['Expected_Wins'] = test_df['G'] * (test_df['R'] ** 2) / ((test_df['R'] ** 2) + (test_df['RA'] ** 2))\n",
    "print(f\"\\nCreated derived feature: Expected_Wins\")   \n",
    "print(f\"Train - Expected_Wins range: {train_df['Expected_Wins'].min():.3f} to {train_df['Expected_Wins'].max():.3f}\")\n",
    "print(f\"Test - Expected_Wins range: {test_df['Expected_Wins'].min():.3f} to {test_df['Expected_Wins'].max():.3f}\")\n",
    "\n",
    "# Times getting on base\n",
    "train_df['Times_On_Base'] = train_df['H'] + train_df['BB']\n",
    "test_df['Times_On_Base'] = test_df['H'] + test_df['BB']\n",
    "\n",
    "print(f\"\\nCreated derived feature: Times_On_Base\")\n",
    "print(f\"Train - Times_On_Base range: {train_df['Times_On_Base'].min():.3f} to {train_df['Times_On_Base'].max():.3f}\")\n",
    "print(f\"Test - Times_On_Base range: {test_df['Times_On_Base'].min():.3f} to {test_df['Times_On_Base'].max():.3f}\")\n",
    "\n",
    "# BB Rate (Walk Percentage) - BB / AB + BB\n",
    "train_df['BB_Rate'] = train_df['BB'] / (train_df['AB'] + train_df['BB'])\n",
    "test_df['BB_Rate'] = test_df['BB'] / (test_df['AB'] + test_df['BB'])\n",
    "\n",
    "print(f\"\\nCreated derived feature: BB_Rate\")\n",
    "print(f\"Train - BB_Rate range: {train_df['BB_Rate'].min():.3f} to {train_df['BB_Rate'].max():.3f}\") \n",
    "print(f\"Test - BB_Rate range: {test_df['BB_Rate'].min():.3f} to {test_df['BB_Rate'].max():.3f}\")\n",
    "\n",
    "# Home Run Rate - HR / AB\n",
    "train_df['HR_Rate'] = train_df['HR'] / train_df['AB']\n",
    "test_df['HR_Rate'] = test_df['HR'] / test_df['AB']\n",
    "\n",
    "print(f\"\\nCreated derived feature: HR_Rate\")\n",
    "print(f\"Train - HR_Rate range: {train_df['HR_Rate'].min():.3f} to {train_df['HR_Rate'].max():.3f}\")\n",
    "print(f\"Test - HR_Rate range: {test_df['HR_Rate'].min():.3f} to {test_df['HR_Rate'].max():.3f}\")\n",
    "\n",
    "# On-Base Percentage (OBP) - (H + BB) / (AB + BB)\n",
    "train_df['OBP'] = (train_df['H'] + train_df['BB']) / (train_df['AB'] + train_df['BB'])\n",
    "test_df['OBP'] = (test_df['H'] + test_df['BB']) / (test_df['AB'] + test_df['BB'])\n",
    "\n",
    "print(f\"\\nCreated derived feature: OBP\")\n",
    "print(f\"Train - OBP range: {train_df['OBP'].min():.3f} to {train_df['OBP'].max():.3f}\") \n",
    "print(f\"Test - OBP range: {test_df['OBP'].min():.3f} to {test_df['OBP'].max():.3f}\")\n",
    "\n",
    "# Slugging Percentage (SLG)\n",
    "# Singles = H - (2B + 3B + HR)\n",
    "# Total Bases = Singles + (2 * 2B) + (3 * 3B) + (4 * HR)\n",
    "# SLG = Total Bases / AB\n",
    "Singles_train = train_df['H'] - (train_df['2B'] + train_df['3B'] + train_df['HR'])\n",
    "Total_Bases_train = Singles_train + (2 * train_df['2B']) + (3 * train_df['3B']) + (4 * train_df['HR'])\n",
    "train_df['SLG'] = Total_Bases_train / train_df['AB']  \n",
    "\n",
    "Singles_test = test_df['H'] - (test_df['2B'] + test_df['3B'] + test_df['HR'])\n",
    "Total_Bases_test = Singles_test + (2 * test_df['2B']) + (3 * test_df['3B']) + (4 * test_df['HR'])\n",
    "test_df['SLG'] = Total_Bases_test / test_df['AB']\n",
    "\n",
    "print(f\"\\nCreated derived feature: SLG\")\n",
    "print(f\"Train - SLG range: {train_df['SLG'].min():.3f} to {train_df['SLG'].max():.3f}\") \n",
    "print(f\"Test - SLG range: {test_df['SLG'].min():.3f} to {test_df['SLG'].max():.3f}\")    \n",
    "\n",
    "# Combined On-Base Plus Slugging (OPS) - OBP + SLG\n",
    "train_df['OPS'] = train_df['OBP'] + train_df['SLG']\n",
    "test_df['OPS'] = test_df['OBP'] + test_df['SLG']\n",
    "\n",
    "print(f\"\\nCreated derived feature: OPS\")\n",
    "print(f\"Train - OPS range: {train_df['OPS'].min():.3f} to {train_df['OPS'].max():.3f}\") \n",
    "print(f\"Test - OPS range: {test_df['OPS'].min():.3f} to {test_df['OPS'].max():.3f}\")\n",
    "\n",
    "# Time on Base Allowed - HA + BBA\n",
    "train_df['Times_On_Base_Allowed'] = train_df['HA'] + train_df['BBA']\n",
    "test_df['Times_On_Base_Allowed'] = test_df['HA'] + test_df['BBA']\n",
    "\n",
    "print(f\"\\nCreated derived feature: Times_On_Base_Allowed\")\n",
    "print(f\"Train - Times_On_Base_Allowed range: {train_df['Times_On_Base_Allowed'].min():.3f} to {train_df['Times_On_Base_Allowed'].max():.3f}\")\n",
    "print(f\"Test - Times_On_Base_Allowed range: {test_df['Times_On_Base_Allowed'].min():.3f} to {test_df['Times_On_Base_Allowed'].max():.3f}\")\n",
    "\n",
    "# WHIP (Walks plus Hits per Inning Pitched)\n",
    "# Inings Pitched = IPouts / 3\n",
    "# Times_On_Base_Per_Inning = Times_On_Base_Allowed / Inings_Pitched\n",
    "train_df['Innings_Pitched'] = train_df['IPouts'] / 3\n",
    "train_df['WHIP'] = train_df['Times_On_Base_Allowed'] / train_df['Innings_Pitched']\n",
    "test_df['Innings_Pitched'] = test_df['IPouts'] / 3\n",
    "test_df['WHIP'] = test_df['Times_On_Base_Allowed'] / test_df['Innings_Pitched']\n",
    "\n",
    "print(f\"\\nCreated derived feature: WHIP\")\n",
    "print(f\"Train - WHIP range: {train_df['WHIP'].min():.3f} to {train_df['WHIP'].max():.3f}\")\n",
    "print(f\"Test - WHIP range: {test_df['WHIP'].min():.3f} to {test_df['WHIP'].max():.3f}\")\n",
    "\n",
    "# K/9 (Strikeouts per 9 Innings) - SOA / Innings_Pitched * 9\n",
    "train_df['K_per_9'] = (train_df['SOA'] / train_df['Innings_Pitched']) * 9\n",
    "test_df['K_per_9'] = (test_df['SOA'] / test_df['Innings_Pitched']) * 9  \n",
    "\n",
    "print(f\"\\nCreated derived feature: K_per_9\")\n",
    "print(f\"Train - K_per_9 range: {train_df['K_per_9'].min():.3f} to {train_df['K_per_9'].max():.3f}\")\n",
    "print(f\"Test - K_per_9 range: {test_df['K_per_9'].min():.3f} to {test_df['K_per_9'].max():.3f}\")\n",
    "\n",
    "# HR/9 (Home Runs Allowed per 9 Innings) - HRA / Innings_Pitched * 9\n",
    "train_df['HR_per_9'] = (train_df['HRA'] / train_df['Innings_Pitched']) * 9\n",
    "test_df['HR_per_9'] = (test_df['HRA'] / test_df['Innings_Pitched']) * 9\n",
    "\n",
    "print(f\"\\nCreated derived feature: HR_per_9\")\n",
    "print(f\"Train - HR_per_9 range: {train_df['HR_per_9'].min():.3f} to {train_df['HR_per_9'].max():.3f}\")\n",
    "print(f\"Test - HR_per_9 range: {test_df['HR_per_9'].min():.3f} to {test_df['HR_per_9'].max():.3f}\")\n",
    "\n",
    "# Run Environment Idex (REI) - (R + RA) / G / mlb_rpg\n",
    "train_df['REI'] = (train_df['R'] + train_df['RA']) / train_df['G'] / train_df['mlb_rpg']\n",
    "test_df['REI'] = (test_df['R'] + test_df['RA']) / test_df['G'] / test_df['mlb_rpg']\n",
    "print(f\"\\nCreated derived feature: REI\")\n",
    "print(f\"Train - REI range: {train_df['REI'].min():.3f} to {train_df['REI'].max():.3f}\")\n",
    "print(f\"Test - REI range: {test_df['REI'].min():.3f} to {test_df['REI'].max():.3f}\")    \n",
    "\n",
    "# Power Environement Index (PEI) -  (HR + HRA) / G / (mlb_rpg * avg_hr_rate)\n",
    "avg_hr_rate = train_df['HR_Rate'].mean()\n",
    "train_df['PEI'] = (train_df['HR'] + train_df['HRA']) / train_df['G'] / (train_df['mlb_rpg'] * avg_hr_rate)\n",
    "test_df['PEI'] = (test_df['HR'] + test_df['HRA']) / test_df['G'] / (test_df['mlb_rpg'] * avg_hr_rate)\n",
    "print(f\"\\nCreated derived feature: PEI\")\n",
    "print(f\"Train - PEI range: {train_df['PEI'].min():.3f} to {train_df['PEI'].max():.3f}\")\n",
    "print(f\"Test - PEI range: {test_df['PEI'].min():.3f} to {test_df['PEI'].max():.3f}\") \n",
    "\n",
    "# Era adjusted OBP, SLG, OPS, WHIP, K_per_9, HR_per_9, BB_Rate, HR_Rate\n",
    "# Historical average runs per game (RPG) for MLB\n",
    "historical_avg_rpg_train = train_df['mlb_rpg'].mean()\n",
    "historical_avg_rpg_test = test_df['mlb_rpg'].mean()\n",
    "# historical_avg_rpg_train = 4.4\n",
    "# historical_avg_rpg_test = 4.4\n",
    "\n",
    "# Era adjusted OBP\n",
    "train_df['Era_Adjusted_OBP'] = train_df['OBP'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_OBP'] = test_df['OBP'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_OBP\")\n",
    "print(f\"Train - Era_Adjusted_OBP range: {train_df['Era_Adjusted_OBP'].min():.3f} to {train_df['Era_Adjusted_OBP'].max():.3f}\") \n",
    "print(f\"Test - Era_Adjusted_OBP range: {test_df['Era_Adjusted_OBP'].min():.3f} to {test_df['Era_Adjusted_OBP'].max():.3f}\") \n",
    "\n",
    "# Era adjusted SLG\n",
    "train_df['Era_Adjusted_SLG'] = train_df['SLG'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_SLG'] = test_df['SLG'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_SLG\")\n",
    "print(f\"Train - Era_Adjusted_SLG range: {train_df['Era_Adjusted_SLG'].min():.3f} to {train_df['Era_Adjusted_SLG'].max():.3f}\") \n",
    "print(f\"Test - Era_Adjusted_SLG range: {test_df['Era_Adjusted_SLG'].min():.3f} to {test_df['Era_Adjusted_SLG'].max():.3f}\") \n",
    "\n",
    "# Era adjusted OPS\n",
    "train_df['Era_Adjusted_OPS'] = train_df['OPS'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_OPS'] = test_df['OPS'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_OPS\")\n",
    "print(f\"Train - Era_Adjusted_OPS range: {train_df['Era_Adjusted_OPS'].min():.3f} to {train_df['Era_Adjusted_OPS'].max():.3f}\") \n",
    "print(f\"Test - Era_Adjusted_OPS range: {test_df['Era_Adjusted_OPS'].min():.3f} to {test_df['Era_Adjusted_OPS'].max():.3f}\")\n",
    "\n",
    "# Era adjusted WHIP\n",
    "train_df['Era_Adjusted_WHIP'] = train_df['WHIP'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_WHIP'] = test_df['WHIP'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_WHIP\")\n",
    "print(f\"Train - Era_Adjusted_WHIP range: {train_df['Era_Adjusted_WHIP'].min():.3f} to {train_df['Era_Adjusted_WHIP'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_WHIP range: {test_df['Era_Adjusted_WHIP'].min():.3f} to {test_df['Era_Adjusted_WHIP'].max():.3f}\")\n",
    "\n",
    "# Era adjusted K_per_9\n",
    "train_df['Era_Adjusted_K_per_9'] = train_df['K_per_9'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_K_per_9'] = test_df['K_per_9'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_K_per_9\")\n",
    "print(f\"Train - Era_Adjusted_K_per_9 range: {train_df['Era_Adjusted_K_per_9'].min():.3f} to {train_df['Era_Adjusted_K_per_9'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_K_per_9 range: {test_df['Era_Adjusted_K_per_9'].min():.3f} to {test_df['Era_Adjusted_K_per_9'].max():.3f}\") \n",
    "\n",
    "# Era adjusted HR_per_9\n",
    "train_df['Era_Adjusted_HR_per_9'] = train_df['HR_per_9'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_HR_per_9'] = test_df['HR_per_9'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_HR_per_9\")\n",
    "print(f\"Train - Era_Adjusted_HR_per_9 range: {train_df['Era_Adjusted_HR_per_9'].min():.3f} to {train_df['Era_Adjusted_HR_per_9'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_HR_per_9 range: {test_df['Era_Adjusted_HR_per_9'].min():.3f} to {test_df['Era_Adjusted_HR_per_9'].max():.3f}\")\n",
    "\n",
    "# Era adjusted BB_Rate\n",
    "train_df['Era_Adjusted_BB_Rate'] = train_df['BB_Rate'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_BB_Rate'] = test_df['BB_Rate'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_BB_Rate\")\n",
    "print(f\"Train - Era_Adjusted_BB_Rate range: {train_df['Era_Adjusted_BB_Rate'].min():.3f} to {train_df['Era_Adjusted_BB_Rate'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_BB_Rate range: {test_df['Era_Adjusted_BB_Rate'].min():.3f} to {test_df['Era_Adjusted_BB_Rate'].max():.3f}\") \n",
    "\n",
    "# Era adjusted HR_Rate\n",
    "train_df['Era_Adjusted_HR_Rate'] = train_df['HR_Rate'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_HR_Rate'] = test_df['HR_Rate'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_HR_Rate\")\n",
    "print(f\"Train - Era_Adjusted_HR_Rate range: {train_df['Era_Adjusted_HR_Rate'].min():.3f} to {train_df['Era_Adjusted_HR_Rate'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_HR_Rate range: {test_df['Era_Adjusted_HR_Rate'].min():.3f} to {test_df['Era_Adjusted_HR_Rate'].max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d71b7c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available default features: 65\n",
      "Available features:\n",
      "G\n",
      "R\n",
      "AB\n",
      "H\n",
      "2B\n",
      "3B\n",
      "HR\n",
      "BB\n",
      "SO\n",
      "SB\n",
      "RA\n",
      "ER\n",
      "ERA\n",
      "CG\n",
      "SHO\n",
      "SV\n",
      "IPouts\n",
      "HA\n",
      "HRA\n",
      "BBA\n",
      "SOA\n",
      "E\n",
      "DP\n",
      "FP\n",
      "Expected_Wins\n",
      "Times_On_Base\n",
      "Times_On_Base_Allowed\n",
      "mlb_rpg\n",
      "Era_Adjusted_OBP\n",
      "Era_Adjusted_SLG\n",
      "Era_Adjusted_OPS\n",
      "Era_Adjusted_WHIP\n",
      "Era_Adjusted_K_per_9\n",
      "Era_Adjusted_HR_per_9\n",
      "Era_Adjusted_BB_Rate\n",
      "Era_Adjusted_HR_Rate\n",
      "OBP\n",
      "SLG\n",
      "OPS\n",
      "WHIP\n",
      "K_per_9\n",
      "HR_per_9\n",
      "BB_Rate\n",
      "HR_Rate\n",
      "PEI\n",
      "REI\n",
      "era_1\n",
      "era_2\n",
      "era_3\n",
      "era_4\n",
      "era_5\n",
      "era_6\n",
      "era_7\n",
      "era_8\n",
      "decade_1910\n",
      "decade_1920\n",
      "decade_1930\n",
      "decade_1940\n",
      "decade_1950\n",
      "decade_1960\n",
      "decade_1970\n",
      "decade_1980\n",
      "decade_1990\n",
      "decade_2000\n",
      "decade_2010\n"
     ]
    }
   ],
   "source": [
    "# Select only the default features from DATA_DESCRIPTION.md\n",
    "# default_features = [\n",
    "#     # Basic Statistics\n",
    "#     'G', 'HR', 'SHO', 'SV', 'IPouts', 'FP', 'ERA', 'ER', 'E',\n",
    "\n",
    "#     # Derived Features\n",
    "#     'Expected_Wins', 'Times_On_Base', 'BB_Rate', 'HR_Rate', 'OPS', 'Times_On_Base_Allowed', \n",
    "#     'WHIP', 'K_per_9', 'HR_per_9', 'mlb_rpg',\n",
    "    \n",
    "#     # Era Indicators\n",
    "#     'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8',\n",
    "    \n",
    "#     # Decade Indicators\n",
    "#     'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950',\n",
    "#     'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010'\n",
    "# ]\n",
    "\n",
    "# default_features = [\n",
    "#     # Basic Statistics\n",
    "#     'G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'CS', 'HBP', 'SF',\n",
    "#     'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA',\n",
    "#     'E', 'DP', 'FP', 'attendance', 'BPF', 'PPF',\n",
    "    \n",
    "#     # Derived Features\n",
    "#     'Expected_Wins', 'Times_On_Base', 'Times_On_Base_Allowed', 'mlb_rpg',\n",
    "\n",
    "#     # 'Era_Adjusted_OBP', 'Era_Adjusted_SLG', 'Era_Adjusted_OPS', 'Era_Adjusted_WHIP',\n",
    "#     # 'Era_Adjusted_K_per_9', 'Era_Adjusted_HR_per_9', 'Era_Adjusted_BB_Rate', 'Era_Adjusted_HR_Rate',\n",
    "#     'BB_Rate', 'HR_Rate', 'OBP', 'SLG', 'OPS', 'WHIP', 'K_per_9', 'HR_per_9',\n",
    "    \n",
    "#     # 'PEI', 'REI',\n",
    "    \n",
    "#     # # Era Indicators\n",
    "#     # 'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8',\n",
    "    \n",
    "#     # Decade Indicators\n",
    "#     'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950',\n",
    "#     'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010'\n",
    "#  ]\n",
    "\n",
    "default_features = [\n",
    "    # Basic Statistics\n",
    "    'G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'CS', 'HBP', 'SF',\n",
    "    'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA',\n",
    "    'E', 'DP', 'FP', 'attendance', 'BPF', 'PPF',\n",
    "    \n",
    "    # Derived Features\n",
    "    'Expected_Wins', 'Times_On_Base', 'Times_On_Base_Allowed', 'mlb_rpg',\n",
    "\n",
    "    'Era_Adjusted_OBP', 'Era_Adjusted_SLG', 'Era_Adjusted_OPS', 'Era_Adjusted_WHIP',\n",
    "    'Era_Adjusted_K_per_9', 'Era_Adjusted_HR_per_9', 'Era_Adjusted_BB_Rate', 'Era_Adjusted_HR_Rate',\n",
    "    \n",
    "    'OBP', 'SLG', 'OPS', 'WHIP', 'K_per_9', 'HR_per_9', 'BB_Rate', 'HR_Rate', \n",
    "    \n",
    "    'PEI', 'REI',\n",
    "    \n",
    "    # Era Indicators\n",
    "    'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8',\n",
    "    \n",
    "    # Decade Indicators\n",
    "    'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950',\n",
    "    'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010'\n",
    " ]\n",
    "\n",
    "# Filter features that exist in both training data AND test data\n",
    "available_features = [col for col in default_features \n",
    "                     if col in train_df.columns and col in test_df.columns]\n",
    "print(f\"Number of available default features: {len(available_features)}\")\n",
    "\n",
    "# Print available features in a column\n",
    "print(\"Available features:\")\n",
    "for feature in available_features:\n",
    "    print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5edd8c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1449, 65)\n",
      "Validation set shape: (363, 65)\n",
      "Final test set shape: (453, 65)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data (split the train.csv for model evaluation)\n",
    "X_full = train_df[available_features]\n",
    "y_full = train_df['W']\n",
    "\n",
    "# Split training data into train/validation sets for model evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare final test data for predictions (this has no target variable)\n",
    "X_test_final = test_df[available_features]\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Final test set shape: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a238e942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CORRELATION ANALYSIS\n",
      "==================================================\n",
      "Correlation threshold: 0.95\n",
      "Original features: 65\n",
      "Features to remove: 13\n",
      "\n",
      "Highly correlated features to remove:\n",
      "  • ERA (corr=0.959 with RA)\n",
      "  • FP (corr=0.996 with E)\n",
      "  • Era_Adjusted_K_per_9 (corr=0.953 with SOA)\n",
      "  • Era_Adjusted_HR_per_9 (corr=0.981 with HRA)\n",
      "  • Era_Adjusted_HR_Rate (corr=0.979 with HR)\n",
      "  • OPS (corr=0.969 with SLG)\n",
      "  • K_per_9 (corr=0.999 with SOA)\n",
      "  • HR_per_9 (corr=0.999 with HRA)\n",
      "  • BB_Rate (corr=0.982 with BB)\n",
      "  • HR_Rate (corr=0.999 with HR)\n",
      "  • PEI (corr=0.959 with Era_Adjusted_HR_Rate)\n",
      "  • decade_1910 (corr=1.000 with era_1)\n",
      "  • decade_2010 (corr=1.000 with era_8)\n",
      "\n",
      "Features after removal: 52\n",
      "Features removed: 13\n",
      "Dimensionality reduction: 20.0%\n",
      "\n",
      "📊 UPDATED DATASET INFO\n",
      "==================================================\n",
      "X_full shape: (1812, 52)\n",
      "X_test_final shape: (453, 52)\n",
      "Available features updated: 52\n",
      "✅ Feature alignment verified between train and test sets\n",
      "\n",
      "🔄 Variables updated for downstream compatibility:\n",
      "  • X_full: (1812, 52)\n",
      "  • X_test_final: (453, 52)\n",
      "  • available_features: 52 features\n",
      "\n",
      "💡 To disable correlation removal, simply comment out this entire cell\n"
     ]
    }
   ],
   "source": [
    "# Remove highly correlated features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def remove_correlated_features(X_train, X_test, threshold=0.95, verbose=True):\n",
    "    \"\"\"\n",
    "    Remove highly correlated features from training and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training feature DataFrame\n",
    "    - X_test: Test feature DataFrame  \n",
    "    - threshold: Correlation threshold (default 0.95)\n",
    "    - verbose: Print information about removed features\n",
    "    \n",
    "    Returns:\n",
    "    - X_train_filtered, X_test_filtered: DataFrames with correlated features removed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    \n",
    "    # Find pairs of highly correlated features\n",
    "    upper_tri = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # Find features to remove (those with correlation > threshold)\n",
    "    features_to_remove = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"🔍 CORRELATION ANALYSIS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Correlation threshold: {threshold}\")\n",
    "        print(f\"Original features: {X_train.shape[1]}\")\n",
    "        print(f\"Features to remove: {len(features_to_remove)}\")\n",
    "        \n",
    "        if features_to_remove:\n",
    "            print(f\"\\nHighly correlated features to remove:\")\n",
    "            for feature in features_to_remove:\n",
    "                # Find what it's correlated with\n",
    "                high_corr = upper_tri[feature].dropna()\n",
    "                high_corr = high_corr[high_corr > threshold]\n",
    "                if len(high_corr) > 0:\n",
    "                    corr_with = high_corr.index[0]\n",
    "                    corr_value = high_corr.iloc[0]\n",
    "                    print(f\"  • {feature} (corr={corr_value:.3f} with {corr_with})\")\n",
    "        else:\n",
    "            print(f\"\\n✅ No highly correlated features found above threshold {threshold}\")\n",
    "    \n",
    "    # Remove highly correlated features from both datasets\n",
    "    X_train_filtered = X_train.drop(columns=features_to_remove)\n",
    "    X_test_filtered = X_test.drop(columns=features_to_remove)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nFeatures after removal: {X_train_filtered.shape[1]}\")\n",
    "        print(f\"Features removed: {len(features_to_remove)}\")\n",
    "        if len(features_to_remove) > 0:\n",
    "            improvement = len(features_to_remove) / X_train.shape[1] * 100\n",
    "            print(f\"Dimensionality reduction: {improvement:.1f}%\")\n",
    "    \n",
    "    return X_train_filtered, X_test_filtered\n",
    "\n",
    "# Apply correlation removal to our datasets\n",
    "# Store original datasets for backup\n",
    "X_full_original = X_full.copy()\n",
    "X_test_final_original = X_test_final.copy()\n",
    "\n",
    "# Remove correlated features\n",
    "X_full_filtered, X_test_final_filtered = remove_correlated_features(\n",
    "    X_full, X_test_final, \n",
    "    threshold=0.95, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Update the main datasets (so later cells use the filtered versions)\n",
    "X_full = X_full_filtered\n",
    "X_test_final = X_test_final_filtered\n",
    "\n",
    "# Update available_features list to match the filtered features\n",
    "available_features_filtered = list(X_full.columns)\n",
    "\n",
    "print(f\"\\n📊 UPDATED DATASET INFO\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"X_full shape: {X_full.shape}\")\n",
    "print(f\"X_test_final shape: {X_test_final.shape}\")\n",
    "print(f\"Available features updated: {len(available_features_filtered)}\")\n",
    "\n",
    "# Verify both datasets have the same features\n",
    "assert list(X_full.columns) == list(X_test_final.columns), \"Feature mismatch between train and test!\"\n",
    "print(f\"✅ Feature alignment verified between train and test sets\")\n",
    "\n",
    "# Update available_features for downstream compatibility\n",
    "available_features = available_features_filtered\n",
    "\n",
    "print(f\"\\n🔄 Variables updated for downstream compatibility:\")\n",
    "print(f\"  • X_full: {X_full.shape}\")\n",
    "print(f\"  • X_test_final: {X_test_final.shape}\")  \n",
    "print(f\"  • available_features: {len(available_features)} features\")\n",
    "print(f\"\\n💡 To disable correlation removal, simply comment out this entire cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c37fccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTUNA-OPTIMIZED BOOSTING MODELS COMPARISON\n",
      "============================================================\n",
      "\n",
      "Dataset shape: (1812, 52)\n",
      "Features being used: ['G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'RA', 'ER', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA', 'E', 'DP', 'Expected_Wins', 'Times_On_Base', 'Times_On_Base_Allowed', 'mlb_rpg', 'Era_Adjusted_OBP', 'Era_Adjusted_SLG', 'Era_Adjusted_OPS', 'Era_Adjusted_WHIP', 'Era_Adjusted_BB_Rate', 'OBP', 'SLG', 'WHIP', 'REI', 'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950', 'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000']\n",
      "\n",
      "🔍 HYPERPARAMETER OPTIMIZATION\n",
      "--------------------------------------------------\n",
      "\n",
      "Optimizing XGBoost hyperparameters...\n",
      "  Best MAE: 3.0262 (Time: 21.6s)\n",
      "\n",
      "Optimizing CatBoost hyperparameters...\n",
      "  Best MAE: 3.0056 (Time: 180.4s)\n",
      "\n",
      "📋 OPTIMIZATION SUMMARY\n",
      "--------------------------------------------------\n",
      "XGBoost:\n",
      "  Best CV MAE: 3.0262\n",
      "  Optimization time: 21.6s\n",
      "  Trials completed: 50\n",
      "\n",
      "CatBoost:\n",
      "  Best CV MAE: 3.0056\n",
      "  Optimization time: 180.4s\n",
      "  Trials completed: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import boosting libraries and Optuna\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import time\n",
    "import warnings\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Silence warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"optuna\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(\"OPTUNA-OPTIMIZED BOOSTING MODELS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data\n",
    "X = X_full\n",
    "y = y_full\n",
    "\n",
    "print(f\"\\nDataset shape: {X.shape}\")\n",
    "print(f\"Features being used: {list(X.columns)}\")\n",
    "\n",
    "# Define objective functions for Optuna hyperparameter optimization\n",
    "def xgboost_objective(trial):\n",
    "    \"\"\"Objective function for XGBoost hyperparameter tuning\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0,\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    \n",
    "    # Try GPU first, fallback to CPU if needed\n",
    "    try:\n",
    "        params['device'] = 'cuda'\n",
    "        model = XGBRegressor(**params)\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "    except:\n",
    "        params['device'] = 'cpu'\n",
    "        model = XGBRegressor(**params)\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    \n",
    "    return -scores.mean()  # Optuna minimizes, so negate MAE\n",
    "\n",
    "def catboost_objective(trial):\n",
    "    \"\"\"Objective function for CatBoost hyperparameter tuning\"\"\"\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 300),\n",
    "        'depth': trial.suggest_int('depth', 3, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10.0),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_seed': 42,\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    # Try GPU first, fallback to CPU if needed\n",
    "    try:\n",
    "        params['task_type'] = 'GPU'\n",
    "        model = CatBoostRegressor(**params)\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "    except:\n",
    "        params['task_type'] = 'CPU'\n",
    "        model = CatBoostRegressor(**params)\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    \n",
    "    return -scores.mean()\n",
    "\n",
    "# Optimize hyperparameters for each model\n",
    "print(\"\\n🔍 HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "optimized_params = {}\n",
    "optimization_results = {}\n",
    "\n",
    "# XGBoost optimization\n",
    "print(\"\\nOptimizing XGBoost hyperparameters...\")\n",
    "start_time = time.time()\n",
    "xgb_study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "xgb_study.optimize(xgboost_objective, n_trials=50, show_progress_bar=False)\n",
    "xgb_time = time.time() - start_time\n",
    "\n",
    "optimized_params['XGBoost'] = xgb_study.best_params\n",
    "optimization_results['XGBoost'] = {\n",
    "    'best_mae': xgb_study.best_value,\n",
    "    'optimization_time': xgb_time,\n",
    "    'n_trials': len(xgb_study.trials)\n",
    "}\n",
    "print(f\"  Best MAE: {xgb_study.best_value:.4f} (Time: {xgb_time:.1f}s)\")\n",
    "\n",
    "# CatBoost optimization\n",
    "print(\"\\nOptimizing CatBoost hyperparameters...\")\n",
    "start_time = time.time()\n",
    "cat_study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "cat_study.optimize(catboost_objective, n_trials=50, show_progress_bar=False)\n",
    "cat_time = time.time() - start_time\n",
    "\n",
    "optimized_params['CatBoost'] = cat_study.best_params\n",
    "optimization_results['CatBoost'] = {\n",
    "    'best_mae': cat_study.best_value,\n",
    "    'optimization_time': cat_time,\n",
    "    'n_trials': len(cat_study.trials)\n",
    "}\n",
    "print(f\"  Best MAE: {cat_study.best_value:.4f} (Time: {cat_time:.1f}s)\")\n",
    "\n",
    "print(f\"\\n📋 OPTIMIZATION SUMMARY\")\n",
    "print(\"-\" * 50)\n",
    "for model_name, result in optimization_results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Best CV MAE: {result['best_mae']:.4f}\")\n",
    "    print(f\"  Optimization time: {result['optimization_time']:.1f}s\")\n",
    "    print(f\"  Trials completed: {result['n_trials']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42bf2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏗️ BUILDING OPTIMIZED MODELS\n",
      "--------------------------------------------------\n",
      "\n",
      "Building optimized XGBoost...\n",
      "  ✅ GPU | CV MAE: 3.0306\n",
      "\n",
      "Building optimized CatBoost...\n",
      "  ✅ GPU | CV MAE: 3.0077\n",
      "\n",
      "==========================================================================================\n",
      "OPTIMIZED MODELS RESULTS SUMMARY\n",
      "==========================================================================================\n",
      "Model                  Test R²    Test MAE    Overfitting   Time (s)   GPU       \n",
      "------------------------------------------------------------------------------------------\n",
      "CatBoost               0.9149    3.0077     0.0350 ✓        4.8    🚀\n",
      "XGBoost                0.9146    3.0306     0.0324 ✓        0.5    🚀\n",
      "\n",
      "🎯 INTELLIGENT MODEL SELECTION (Balancing Performance & Overfitting)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Selected Model: CatBoost\n",
      "Selection Reason: Selected for low overfitting (0.0350) with minimal MAE penalty (0.0000)\n",
      "MAE: 3.0077, Overfitting: 0.0350\n",
      "\n",
      "🏆 BEST OPTIMIZED MODEL: CatBoost\n",
      "   CV MAE: 3.0077 (±0.0861)\n",
      "   CV R²: 0.9149 (±0.0054)\n",
      "   Overfitting: 0.0350 (✓ Acceptable)\n",
      "\n",
      "🔧 OPTIMIZED PARAMETERS FOR CatBoost:\n",
      "----------------------------------------\n",
      "  iterations: 170\n",
      "  depth: 6\n",
      "  learning_rate: 0.0714\n",
      "  l2_leaf_reg: 9.1746\n",
      "  bagging_temperature: 0.8502\n",
      "  random_strength: 0.0529\n",
      "  border_count: 71\n",
      "\n",
      "📊 FEATURE IMPORTANCE (CatBoost)\n",
      "----------------------------------------\n",
      "Training CatBoost on full dataset for feature importance...\n",
      "\n",
      "Top 15 Features:\n",
      "         Expected_Wins: 75.8354\n",
      "                    SV: 8.3463\n",
      "                    CG: 1.8056\n",
      "                   SHO: 1.6801\n",
      "                   OBP: 1.4831\n",
      "     Era_Adjusted_WHIP: 0.9315\n",
      "                IPouts: 0.9288\n",
      "                    3B: 0.7382\n",
      "                    AB: 0.5502\n",
      "                   BBA: 0.5125\n",
      "                    SB: 0.5060\n",
      "      Era_Adjusted_SLG: 0.4609\n",
      "                   REI: 0.4239\n",
      "  Era_Adjusted_BB_Rate: 0.4226\n",
      "                    SO: 0.4089\n",
      "\n",
      "✨ OPTIMIZATION COMPLETE!\n",
      "   Best model improved MAE through Optuna hyperparameter tuning\n",
      "   Ready for ensemble or final predictions\n"
     ]
    }
   ],
   "source": [
    "# Build models with optimized parameters and perform detailed comparison\n",
    "print(\"\\n🏗️ BUILDING OPTIMIZED MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create models with optimized parameters\n",
    "def create_optimized_model(model_name, params):\n",
    "    \"\"\"Create a model instance with optimized parameters\"\"\"\n",
    "    if model_name == 'XGBoost':\n",
    "        # Try GPU first, fallback to CPU\n",
    "        try:\n",
    "            params_gpu = params.copy()\n",
    "            params_gpu['device'] = 'cuda'\n",
    "            params_gpu['tree_method'] = 'hist'\n",
    "            params_gpu['verbosity'] = 0\n",
    "            model = XGBRegressor(**params_gpu)\n",
    "            # Test if GPU works\n",
    "            model.fit(X[:100], y[:100])\n",
    "            return model, '✅ GPU'\n",
    "        except:\n",
    "            params_cpu = params.copy()\n",
    "            params_cpu['device'] = 'cpu'\n",
    "            params_cpu['tree_method'] = 'hist' \n",
    "            params_cpu['verbosity'] = 0\n",
    "            return XGBRegressor(**params_cpu), '⚠️ CPU'\n",
    "            \n",
    "    elif model_name == 'CatBoost':\n",
    "        try:\n",
    "            params_gpu = params.copy()\n",
    "            params_gpu['task_type'] = 'GPU'\n",
    "            params_gpu['verbose'] = False\n",
    "            model = CatBoostRegressor(**params_gpu)\n",
    "            # Test if GPU works\n",
    "            model.fit(X[:100], y[:100])\n",
    "            return model, '✅ GPU'\n",
    "        except:\n",
    "            params_cpu = params.copy()\n",
    "            params_cpu['task_type'] = 'CPU'\n",
    "            params_cpu['verbose'] = False\n",
    "            return CatBoostRegressor(**params_cpu), '⚠️ CPU'\n",
    "\n",
    "# Build optimized models\n",
    "optimized_models = {}\n",
    "cv_results_optimized = {}\n",
    "\n",
    "for name, params in optimized_params.items():\n",
    "    print(f\"\\nBuilding optimized {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model, gpu_status = create_optimized_model(name, params)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate(\n",
    "        model, X, y,\n",
    "        cv=5,\n",
    "        scoring=['r2', 'neg_mean_absolute_error'],\n",
    "        return_train_score=True,\n",
    "        n_jobs=1 if 'GPU' in gpu_status else -1\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    cv_results_optimized[name] = {\n",
    "        'test_r2': cv_scores['test_r2'].mean(),\n",
    "        'test_r2_std': cv_scores['test_r2'].std(),\n",
    "        'test_mae': -cv_scores['test_neg_mean_absolute_error'].mean(),\n",
    "        'test_mae_std': cv_scores['test_neg_mean_absolute_error'].std(),\n",
    "        'train_r2': cv_scores['train_r2'].mean(),\n",
    "        'overfitting': cv_scores['train_r2'].mean() - cv_scores['test_r2'].mean(),\n",
    "        'time': end_time - start_time,\n",
    "        'gpu_status': gpu_status\n",
    "    }\n",
    "    \n",
    "    optimized_models[name] = model\n",
    "    print(f\"  {gpu_status} | CV MAE: {cv_results_optimized[name]['test_mae']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"OPTIMIZED MODELS RESULTS SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Model':<22} {'Test R²':<10} {'Test MAE':<11} {'Overfitting':<13} {'Time (s)':<10} {'GPU':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Sort by Test MAE (lower is better) for initial ranking\n",
    "sorted_results = sorted(cv_results_optimized.items(), key=lambda x: x[1]['test_mae'])\n",
    "\n",
    "for name, result in sorted_results:\n",
    "    overfit_warning = \"⚠️\" if result['overfitting'] > 0.05 else \"✓\"\n",
    "    gpu_icon = \"🚀\" if \"GPU\" in result['gpu_status'] else \"💻\"\n",
    "    print(f\"{name:<22} {result['test_r2']:.4f}    {result['test_mae']:.4f}     \"\n",
    "          f\"{result['overfitting']:>6.4f} {overfit_warning:<5} {result['time']:>6.1f}    {gpu_icon}\")\n",
    "\n",
    "print(f\"\\n🎯 INTELLIGENT MODEL SELECTION (Balancing Performance & Overfitting)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Select best model considering both performance and overfitting\n",
    "def select_best_model_with_overfitting_control(results, overfitting_threshold=0.05, mae_tolerance=0.01):\n",
    "    \"\"\"\n",
    "    Select the best model balancing performance and overfitting.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary of model results\n",
    "        overfitting_threshold: Maximum acceptable overfitting gap (train_r2 - test_r2)\n",
    "        mae_tolerance: MAE tolerance for accepting a less overfitting model over the best performer\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (best_model_name, reason)\n",
    "    \"\"\"\n",
    "    # Sort by MAE first\n",
    "    sorted_by_mae = sorted(results.items(), key=lambda x: x[1]['test_mae'])\n",
    "    \n",
    "    # Find models that don't overfit significantly\n",
    "    non_overfitting_models = [\n",
    "        (name, result) for name, result in sorted_by_mae \n",
    "        if result['overfitting'] <= overfitting_threshold\n",
    "    ]\n",
    "    \n",
    "    best_mae_model = sorted_by_mae[0]\n",
    "    best_mae = best_mae_model[1]['test_mae']\n",
    "    \n",
    "    if non_overfitting_models:\n",
    "        # Check if the best non-overfitting model is within acceptable MAE tolerance\n",
    "        best_non_overfit = non_overfitting_models[0]\n",
    "        mae_diff = best_non_overfit[1]['test_mae'] - best_mae\n",
    "        \n",
    "        if mae_diff <= mae_tolerance:\n",
    "            return best_non_overfit[0], f\"Selected for low overfitting ({best_non_overfit[1]['overfitting']:.4f}) with minimal MAE penalty ({mae_diff:.4f})\"\n",
    "        else:\n",
    "            # Check if the best MAE model overfits significantly\n",
    "            if best_mae_model[1]['overfitting'] > overfitting_threshold:\n",
    "                return best_non_overfit[0], f\"Selected to avoid overfitting. Best MAE model overfits by {best_mae_model[1]['overfitting']:.4f}\"\n",
    "            else:\n",
    "                return best_mae_model[0], f\"Selected for best MAE ({best_mae:.4f}) with acceptable overfitting ({best_mae_model[1]['overfitting']:.4f})\"\n",
    "    else:\n",
    "        # All models overfit, choose the one with least overfitting among top performers\n",
    "        print(\"  ⚠️ All models show overfitting. Selecting least overfitting among top 3 MAE performers.\")\n",
    "        top_3_mae = sorted_by_mae[:3]\n",
    "        least_overfit_of_top3 = min(top_3_mae, key=lambda x: x[1]['overfitting'])\n",
    "        return least_overfit_of_top3[0], f\"Least overfitting ({least_overfit_of_top3[1]['overfitting']:.4f}) among top 3 MAE performers\"\n",
    "\n",
    "# Apply intelligent model selection\n",
    "best_model_name, selection_reason = select_best_model_with_overfitting_control(cv_results_optimized)\n",
    "best_model = optimized_models[best_model_name]\n",
    "best_mae = cv_results_optimized[best_model_name]['test_mae']\n",
    "best_overfitting = cv_results_optimized[best_model_name]['overfitting']\n",
    "\n",
    "print(f\"\\nSelected Model: {best_model_name}\")\n",
    "print(f\"Selection Reason: {selection_reason}\")\n",
    "print(f\"MAE: {best_mae:.4f}, Overfitting: {best_overfitting:.4f}\")\n",
    "\n",
    "# Show comparison with pure MAE-based selection\n",
    "pure_mae_best = sorted_results[0][0]\n",
    "if pure_mae_best != best_model_name:\n",
    "    pure_mae_result = cv_results_optimized[pure_mae_best]\n",
    "    print(f\"\\nComparison with pure MAE selection:\")\n",
    "    print(f\"  Pure MAE Best: {pure_mae_best} (MAE: {pure_mae_result['test_mae']:.4f}, Overfitting: {pure_mae_result['overfitting']:.4f})\")\n",
    "    print(f\"  Selected Model: {best_model_name} (MAE: {best_mae:.4f}, Overfitting: {best_overfitting:.4f})\")\n",
    "    mae_diff = best_mae - pure_mae_result['test_mae']\n",
    "    overfit_improvement = pure_mae_result['overfitting'] - best_overfitting\n",
    "    print(f\"  Trade-off: +{mae_diff:.4f} MAE for -{overfit_improvement:.4f} overfitting reduction\")\n",
    "\n",
    "print(f\"\\n🏆 BEST OPTIMIZED MODEL: {best_model_name}\")\n",
    "print(f\"   CV MAE: {best_mae:.4f} (±{cv_results_optimized[best_model_name]['test_mae_std']:.4f})\")\n",
    "print(f\"   CV R²: {cv_results_optimized[best_model_name]['test_r2']:.4f} (±{cv_results_optimized[best_model_name]['test_r2_std']:.4f})\")\n",
    "print(f\"   Overfitting: {best_overfitting:.4f} ({'⚠️' if best_overfitting > 0.05 else '✓'} {'High' if best_overfitting > 0.05 else 'Acceptable'})\")\n",
    "\n",
    "# Display optimized parameters\n",
    "print(f\"\\n🔧 OPTIMIZED PARAMETERS FOR {best_model_name}:\")\n",
    "print(\"-\" * 40)\n",
    "for param, value in optimized_params[best_model_name].items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {param}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "# Feature importance for best model\n",
    "print(f\"\\n📊 FEATURE IMPORTANCE ({best_model_name})\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Training {best_model_name} on full dataset for feature importance...\")\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 15 Features:\")\n",
    "    for i, row in importance_df.head(15).iterrows():\n",
    "        print(f\"  {row['feature']:>20}: {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n✨ OPTIMIZATION COMPLETE!\")\n",
    "print(f\"   Best model improved MAE through Optuna hyperparameter tuning\")\n",
    "print(f\"   Ready for ensemble or final predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebc9b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTUNA-OPTIMIZED LINEAR MODELS COMPARISON\n",
      "============================================================\n",
      "\n",
      "Dataset shape: (1812, 52)\n",
      "Using 52 engineered features\n",
      "\n",
      "🔍 LINEAR MODELS HYPERPARAMETER OPTIMIZATION\n",
      "--------------------------------------------------\n",
      "\n",
      "Optimizing Ridge hyperparameters...\n",
      "  ✅ Best MAE: 2.7194 (Time: 4.1s)\n",
      "\n",
      "Optimizing Lasso hyperparameters...\n",
      "  ✅ Best MAE: 2.7166 (Time: 0.7s)\n",
      "\n",
      "Optimizing ElasticNet hyperparameters...\n",
      "  ✅ Best MAE: 2.7196 (Time: 0.7s)\n",
      "\n",
      "Optimizing Huber hyperparameters...\n",
      "  ✅ Best MAE: 2.7201 (Time: -0.3s)\n",
      "\n",
      "Optimizing Polynomial_Ridge hyperparameters...\n",
      "  ✅ Best MAE: 2.7426 (Time: 15.4s)\n",
      "\n",
      "Testing Linear Regression (no hyperparameters)...\n",
      "  ✅ MAE: 2.7312 (Time: 0.0s)\n",
      "\n",
      "📋 LINEAR MODELS OPTIMIZATION SUMMARY\n",
      "------------------------------------------------------------\n",
      "Ridge:\n",
      "  Best CV MAE: 2.7194\n",
      "  Optimization time: 4.1s\n",
      "  Trials completed: 30\n",
      "\n",
      "Lasso:\n",
      "  Best CV MAE: 2.7166\n",
      "  Optimization time: 0.7s\n",
      "  Trials completed: 30\n",
      "\n",
      "ElasticNet:\n",
      "  Best CV MAE: 2.7196\n",
      "  Optimization time: 0.7s\n",
      "  Trials completed: 30\n",
      "\n",
      "Huber:\n",
      "  Best CV MAE: 2.7201\n",
      "  Optimization time: -0.3s\n",
      "  Trials completed: 30\n",
      "\n",
      "Polynomial_Ridge:\n",
      "  Best CV MAE: 2.7426\n",
      "  Optimization time: 15.4s\n",
      "  Trials completed: 30\n",
      "\n",
      "LinearRegression:\n",
      "  Best CV MAE: 2.7312\n",
      "  Optimization time: 0.0s\n",
      "  Trials completed: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import linear model libraries and continue using Optuna\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, HuberRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Comprehensive warning suppression for clean output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"optuna\") \n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)  # 🔧 Suppress all convergence warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Objective did not converge\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*coordinate_descent.*\")  # 🔧 Suppress coordinate descent warnings\n",
    "\n",
    "print(\"OPTUNA-OPTIMIZED LINEAR MODELS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data\n",
    "X_linear = X_full\n",
    "y_linear = y_full\n",
    "\n",
    "print(f\"\\nDataset shape: {X_linear.shape}\")\n",
    "print(f\"Using {len(available_features)} engineered features\")\n",
    "\n",
    "# Define objective functions for Optuna hyperparameter optimization\n",
    "def ridge_objective(trial):\n",
    "    \"\"\"Objective function for Ridge regression hyperparameter tuning\"\"\"\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 100.0, log=True)\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=alpha, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(model, X_linear, y_linear, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "def lasso_objective(trial):\n",
    "    \"\"\"Objective function for Lasso regression hyperparameter tuning\"\"\"\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 10.0, log=True)  # 🔧 Raised minimum alpha for better convergence\n",
    "    max_iter = trial.suggest_int('max_iter', 10000, 20000)  # 🔧 Much higher iteration range\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(alpha=alpha, max_iter=max_iter, tol=1e-3, random_state=42, warm_start=False))  # 🔧 Relaxed tolerance, no warm start\n",
    "    ])\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")  # 🔧 Local warning suppression\n",
    "        scores = cross_val_score(model, X_linear, y_linear, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "def elasticnet_objective(trial):\n",
    "    \"\"\"Objective function for ElasticNet regression hyperparameter tuning\"\"\"\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 10.0, log=True)  # 🔧 Raised minimum alpha\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.1, 0.9)\n",
    "    max_iter = trial.suggest_int('max_iter', 10000, 20000)  # 🔧 Much higher iteration range\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter, tol=1e-3, random_state=42, warm_start=False))  # 🔧 Relaxed tolerance\n",
    "    ])\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")  # 🔧 Local warning suppression  \n",
    "        scores = cross_val_score(model, X_linear, y_linear, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "def huber_objective(trial):\n",
    "    \"\"\"Objective function for Huber regression hyperparameter tuning\"\"\"\n",
    "    epsilon = trial.suggest_float('epsilon', 1.1, 3.0)\n",
    "    alpha = trial.suggest_float('alpha', 0.0001, 1.0, log=True)\n",
    "    max_iter = trial.suggest_int('max_iter', 1000, 5000)\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', HuberRegressor(epsilon=epsilon, alpha=alpha, max_iter=max_iter, tol=1e-05))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(model, X_linear, y_linear, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "def polynomial_ridge_objective(trial):\n",
    "    \"\"\"Objective function for Polynomial Ridge regression hyperparameter tuning\"\"\"\n",
    "    degree = trial.suggest_int('degree', 2, 3)\n",
    "    alpha = trial.suggest_float('alpha', 0.1, 1000.0, log=True)\n",
    "    include_bias = trial.suggest_categorical('include_bias', [True, False])\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree, include_bias=include_bias)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=alpha, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(model, X_linear, y_linear, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "# Optimize hyperparameters for each linear model\n",
    "print(\"\\n🔍 LINEAR MODELS HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "optimized_linear_params = {}\n",
    "linear_optimization_results = {}\n",
    "\n",
    "# List of models to optimize\n",
    "linear_models_to_optimize = [\n",
    "    ('Ridge', ridge_objective),\n",
    "    ('Lasso', lasso_objective), \n",
    "    ('ElasticNet', elasticnet_objective),\n",
    "    ('Huber', huber_objective),\n",
    "    ('Polynomial_Ridge', polynomial_ridge_objective)\n",
    "]\n",
    "\n",
    "for model_name, objective_func in linear_models_to_optimize:\n",
    "    print(f\"\\nOptimizing {model_name} hyperparameters...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create study for this model\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        sampler=TPESampler(seed=42)\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        study.optimize(objective_func, n_trials=30, show_progress_bar=False)\n",
    "        optimization_time = time.time() - start_time\n",
    "        \n",
    "        optimized_linear_params[model_name] = study.best_params\n",
    "        linear_optimization_results[model_name] = {\n",
    "            'best_mae': study.best_value,\n",
    "            'optimization_time': optimization_time,\n",
    "            'n_trials': len(study.trials),\n",
    "            'status': 'Success'\n",
    "        }\n",
    "        print(f\"  ✅ Best MAE: {study.best_value:.4f} (Time: {optimization_time:.1f}s)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Failed: {str(e)}\")\n",
    "        linear_optimization_results[model_name] = {\n",
    "            'status': 'Failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Also include basic Linear Regression (no hyperparameters to optimize)\n",
    "print(f\"\\nTesting Linear Regression (no hyperparameters)...\")\n",
    "start_time = time.time()\n",
    "linear_reg_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "scores = cross_val_score(linear_reg_model, X_linear, y_linear, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "linear_reg_time = time.time() - start_time\n",
    "\n",
    "optimized_linear_params['LinearRegression'] = {}\n",
    "linear_optimization_results['LinearRegression'] = {\n",
    "    'best_mae': -scores.mean(),\n",
    "    'optimization_time': linear_reg_time,\n",
    "    'n_trials': 1,\n",
    "    'status': 'Success'\n",
    "}\n",
    "print(f\"  ✅ MAE: {-scores.mean():.4f} (Time: {linear_reg_time:.1f}s)\")\n",
    "\n",
    "print(f\"\\n📋 LINEAR MODELS OPTIMIZATION SUMMARY\")\n",
    "print(\"-\" * 60)\n",
    "successful_linear = {k: v for k, v in linear_optimization_results.items() if v.get('status') == 'Success'}\n",
    "for model_name, result in successful_linear.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Best CV MAE: {result['best_mae']:.4f}\")\n",
    "    print(f\"  Optimization time: {result['optimization_time']:.1f}s\")\n",
    "    print(f\"  Trials completed: {result['n_trials']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ca7aa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏗️ BUILDING OPTIMIZED LINEAR MODELS\n",
      "--------------------------------------------------\n",
      "\n",
      "Building optimized Ridge...\n",
      "  ✅ CV MAE: 2.7263\n",
      "\n",
      "Building optimized Lasso...\n",
      "  ✅ CV MAE: 2.7235\n",
      "\n",
      "Building optimized ElasticNet...\n",
      "  ✅ CV MAE: 2.7259\n",
      "\n",
      "Building optimized Huber...\n",
      "  ✅ CV MAE: 2.7261\n",
      "\n",
      "Building optimized Polynomial_Ridge...\n",
      "  ✅ CV MAE: 2.7444\n",
      "\n",
      "Building optimized LinearRegression...\n",
      "  ✅ CV MAE: 2.7448\n",
      "\n",
      "==========================================================================================\n",
      "OPTIMIZED LINEAR MODELS RESULTS SUMMARY\n",
      "==========================================================================================\n",
      "Model                  Test R²    Test MAE    Overfitting   Time (s)  \n",
      "------------------------------------------------------------------------------------------\n",
      "Lasso                  0.9312    2.7235     0.0041 ✓        0.0\n",
      "ElasticNet             0.9311    2.7259     0.0041 ✓        0.0\n",
      "Huber                  0.9309    2.7261     0.0047 ✓        0.0\n",
      "Ridge                  0.9310    2.7263     0.0046 ✓        0.0\n",
      "Polynomial_Ridge       0.9300    2.7444     0.0116 ✓        0.2\n",
      "LinearRegression       0.9301    2.7448     0.0059 ✓        0.0\n",
      "\n",
      "🎯 INTELLIGENT LINEAR MODEL SELECTION\n",
      "--------------------------------------------------\n",
      "\n",
      "Selected Linear Model: Lasso\n",
      "Selection Reason: Selected for low overfitting (0.0041) with minimal MAE penalty (0.0000)\n",
      "MAE: 2.7235, Overfitting: 0.0041\n",
      "\n",
      "🏆 BEST OPTIMIZED LINEAR MODEL: Lasso\n",
      "   CV MAE: 2.7235 (±0.0525)\n",
      "   CV R²: 0.9312 (±0.0068)\n",
      "   Overfitting: 0.0041 (✓ Acceptable)\n",
      "\n",
      "🔧 OPTIMIZED PARAMETERS FOR Lasso:\n",
      "----------------------------------------\n",
      "  alpha: 0.0102\n",
      "  max_iter: 18944\n",
      "\n",
      "🔄 COMPARISON WITH BOOSTING MODELS\n",
      "--------------------------------------------------\n",
      "Best Boosting Model: CatBoost (MAE: 3.0077)\n",
      "Best Linear Model: Lasso (MAE: 2.7235)\n",
      "✅ Linear model outperforms boosting by 0.2843\n",
      "\n",
      "✨ LINEAR OPTIMIZATION COMPLETE!\n",
      "   All linear models optimized with Optuna hyperparameter tuning\n",
      "   Ready for enhanced ensemble with optimized linear models\n"
     ]
    }
   ],
   "source": [
    "# Build optimized linear models and perform detailed comparison\n",
    "print(\"\\n🏗️ BUILDING OPTIMIZED LINEAR MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create models with optimized parameters\n",
    "def create_optimized_linear_model(model_name, params):\n",
    "    \"\"\"Create a linear model instance with optimized parameters\"\"\"\n",
    "    if model_name == 'Ridge':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Ridge(alpha=params['alpha'], random_state=42))\n",
    "        ])\n",
    "    \n",
    "    elif model_name == 'Lasso':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Lasso(\n",
    "                alpha=params['alpha'], \n",
    "                max_iter=params['max_iter'], \n",
    "                tol=1e-4,  # 🔧 Improved tolerance\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "    \n",
    "    elif model_name == 'ElasticNet':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', ElasticNet(\n",
    "                alpha=params['alpha'], \n",
    "                l1_ratio=params['l1_ratio'], \n",
    "                max_iter=params['max_iter'],\n",
    "                tol=1e-4,  # 🔧 Improved tolerance \n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "    \n",
    "    elif model_name == 'Huber':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', HuberRegressor(\n",
    "                epsilon=params['epsilon'],\n",
    "                alpha=params['alpha'],\n",
    "                max_iter=params['max_iter'],\n",
    "                tol=1e-05\n",
    "            ))\n",
    "        ])\n",
    "    \n",
    "    elif model_name == 'Polynomial_Ridge':\n",
    "        return Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=params['degree'], include_bias=params['include_bias'])),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Ridge(alpha=params['alpha'], random_state=42))\n",
    "        ])\n",
    "    \n",
    "    elif model_name == 'LinearRegression':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LinearRegression())\n",
    "        ])\n",
    "\n",
    "# Build optimized linear models\n",
    "optimized_linear_models = {}\n",
    "cv_results_linear_optimized = {}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name in successful_linear.keys():\n",
    "    print(f\"\\nBuilding optimized {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = create_optimized_linear_model(name, optimized_linear_params[name])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate(\n",
    "        model, X_linear, y_linear,\n",
    "        cv=cv,\n",
    "        scoring=['r2', 'neg_mean_absolute_error'],\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    cv_results_linear_optimized[name] = {\n",
    "        'test_r2': cv_scores['test_r2'].mean(),\n",
    "        'test_r2_std': cv_scores['test_r2'].std(),\n",
    "        'test_mae': -cv_scores['test_neg_mean_absolute_error'].mean(),\n",
    "        'test_mae_std': cv_scores['test_neg_mean_absolute_error'].std(),\n",
    "        'train_r2': cv_scores['train_r2'].mean(),\n",
    "        'overfitting': cv_scores['train_r2'].mean() - cv_scores['test_r2'].mean(),\n",
    "        'time': end_time - start_time\n",
    "    }\n",
    "    \n",
    "    optimized_linear_models[name] = model\n",
    "    print(f\"  ✅ CV MAE: {cv_results_linear_optimized[name]['test_mae']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"OPTIMIZED LINEAR MODELS RESULTS SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Model':<22} {'Test R²':<10} {'Test MAE':<11} {'Overfitting':<13} {'Time (s)':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Sort by Test MAE (lower is better)\n",
    "sorted_linear_results = sorted(cv_results_linear_optimized.items(), key=lambda x: x[1]['test_mae'])\n",
    "\n",
    "for name, result in sorted_linear_results:\n",
    "    overfit_warning = \"⚠️\" if result['overfitting'] > 0.05 else \"✓\"\n",
    "    print(f\"{name:<22} {result['test_r2']:.4f}    {result['test_mae']:.4f}     \"\n",
    "          f\"{result['overfitting']:>6.4f} {overfit_warning:<5} {result['time']:>6.1f}\")\n",
    "\n",
    "print(f\"\\n🎯 INTELLIGENT LINEAR MODEL SELECTION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Apply intelligent model selection (similar to boosting models)\n",
    "best_linear_model_name, linear_selection_reason = select_best_model_with_overfitting_control(\n",
    "    cv_results_linear_optimized, \n",
    "    overfitting_threshold=0.05, \n",
    "    mae_tolerance=0.01\n",
    ")\n",
    "best_linear_model = optimized_linear_models[best_linear_model_name]\n",
    "best_linear_mae = cv_results_linear_optimized[best_linear_model_name]['test_mae']\n",
    "best_linear_overfitting = cv_results_linear_optimized[best_linear_model_name]['overfitting']\n",
    "\n",
    "print(f\"\\nSelected Linear Model: {best_linear_model_name}\")\n",
    "print(f\"Selection Reason: {linear_selection_reason}\")\n",
    "print(f\"MAE: {best_linear_mae:.4f}, Overfitting: {best_linear_overfitting:.4f}\")\n",
    "\n",
    "print(f\"\\n🏆 BEST OPTIMIZED LINEAR MODEL: {best_linear_model_name}\")\n",
    "print(f\"   CV MAE: {best_linear_mae:.4f} (±{cv_results_linear_optimized[best_linear_model_name]['test_mae_std']:.4f})\")\n",
    "print(f\"   CV R²: {cv_results_linear_optimized[best_linear_model_name]['test_r2']:.4f} (±{cv_results_linear_optimized[best_linear_model_name]['test_r2_std']:.4f})\")\n",
    "print(f\"   Overfitting: {best_linear_overfitting:.4f} ({'⚠️' if best_linear_overfitting > 0.05 else '✓'} {'High' if best_linear_overfitting > 0.05 else 'Acceptable'})\")\n",
    "\n",
    "# Display optimized parameters\n",
    "if optimized_linear_params[best_linear_model_name]:  # Skip if empty (LinearRegression)\n",
    "    print(f\"\\n🔧 OPTIMIZED PARAMETERS FOR {best_linear_model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for param, value in optimized_linear_params[best_linear_model_name].items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {param}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\n🔄 COMPARISON WITH BOOSTING MODELS\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Best Boosting Model: {best_model_name} (MAE: {best_mae:.4f})\")\n",
    "print(f\"Best Linear Model: {best_linear_model_name} (MAE: {best_linear_mae:.4f})\")\n",
    "\n",
    "if best_linear_mae < best_mae:\n",
    "    print(f\"✅ Linear model outperforms boosting by {best_mae - best_linear_mae:.4f}\")\n",
    "else:\n",
    "    print(f\"⚠️ Boosting model outperforms linear by {best_linear_mae - best_mae:.4f}\")\n",
    "\n",
    "print(f\"\\n✨ LINEAR OPTIMIZATION COMPLETE!\")\n",
    "print(f\"   All linear models optimized with Optuna hyperparameter tuning\")\n",
    "print(f\"   Ready for enhanced ensemble with optimized linear models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc4f5b",
   "metadata": {},
   "source": [
    "# Phase 1: Weighted Ensemble Implementation\n",
    "\n",
    "Based on your individual model results, we'll now implement a weighted ensemble approach to combine the best performing models. This should help us break below the 3.0 MAE barrier by leveraging the strengths of different model types.\n",
    "\n",
    "## Strategy:\n",
    "- Select top performing models from both linear and boosting categories\n",
    "- Use cross-validation performance to determine optimal weights\n",
    "- Weight linear regression higher since it performed best on Kaggle (3.05136)\n",
    "- Generate ensemble predictions for final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bb6133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1: WEIGHTED ENSEMBLE IMPLEMENTATION (OPTUNA-OPTIMIZED)\n",
      "======================================================================\n",
      "\n",
      "1. SELECTING TOP OPTUNA-OPTIMIZED MODELS\n",
      "--------------------------------------------------\n",
      "Top Optuna-Optimized Linear Models (by CV MAE):\n",
      "  Lasso: MAE = 2.7235, R² = 0.9312\n",
      "  ElasticNet: MAE = 2.7259, R² = 0.9311\n",
      "  Huber: MAE = 2.7261, R² = 0.9309\n",
      "\n",
      "Top Optuna-Optimized Boosting Models (by CV MAE):\n",
      "  CatBoost: MAE = 3.0077, R² = 0.9149\n",
      "  XGBoost: MAE = 3.0306, R² = 0.9146\n",
      "\n",
      "2. OPTUNA-ENHANCED ENSEMBLE COMPOSITION\n",
      "--------------------------------------------------\n",
      "Selected 3 Optuna-optimized models for ensemble:\n",
      "  ✅ Lasso (Optuna-optimized)\n",
      "  ✅ ElasticNet (Optuna-optimized)\n",
      "  ✅ CatBoost (Optuna-optimized)\n",
      "\n",
      "Total ensemble models: 3\n",
      "\n",
      "3. OPTUNA-OPTIMIZED MODEL PERFORMANCE SUMMARY\n",
      "--------------------------------------------------\n",
      "Lasso: MAE = 2.7235, R² = 0.9312\n",
      "ElasticNet: MAE = 2.7259, R² = 0.9311\n",
      "CatBoost: MAE = 3.0077, R² = 0.9149\n",
      "\n",
      "4. OPTUNA PARAMETERS IN USE\n",
      "--------------------------------------------------\n",
      "\n",
      "Lasso (Linear):\n",
      "  alpha: 0.0102\n",
      "  max_iter: 18944\n",
      "\n",
      "ElasticNet (Linear):\n",
      "  alpha: 0.0111\n",
      "  l1_ratio: 0.7230\n",
      "  max_iter: 17330\n",
      "\n",
      "CatBoost (Boosting):\n",
      "  iterations: 170\n",
      "  depth: 6\n",
      "  learning_rate: 0.0714\n",
      "  border_count: 71\n",
      "\n",
      "🚀 Using Optuna-optimized models for superior ensemble performance!\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 1: WEIGHTED ENSEMBLE IMPLEMENTATION (OPTUNA-OPTIMIZED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# First, let's identify our top performing models from Optuna optimization\n",
    "print(\"\\n1. SELECTING TOP OPTUNA-OPTIMIZED MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Top 3 linear models (based on CV MAE from Optuna optimization)\n",
    "top_linear_models = dict(sorted(cv_results_linear_optimized.items(), key=lambda x: x[1]['test_mae'])[:3])\n",
    "print(\"Top Optuna-Optimized Linear Models (by CV MAE):\")\n",
    "for name, result in top_linear_models.items():\n",
    "    print(f\"  {name}: MAE = {result['test_mae']:.4f}, R² = {result['test_r2']:.4f}\")\n",
    "\n",
    "# Top 2 boosting models (from Optuna optimization)\n",
    "top_boosting_models = dict(sorted(cv_results_optimized.items(), key=lambda x: x[1]['test_mae'])[:2])\n",
    "print(\"\\nTop Optuna-Optimized Boosting Models (by CV MAE):\")\n",
    "for name, result in top_boosting_models.items():\n",
    "    print(f\"  {name}: MAE = {result['test_mae']:.4f}, R² = {result['test_r2']:.4f}\")\n",
    "\n",
    "# Select our ensemble candidates (top performers from each category)\n",
    "ensemble_models = {}\n",
    "\n",
    "# Add top 2 linear models from Optuna optimization\n",
    "linear_names = list(top_linear_models.keys())[:2]\n",
    "for name in linear_names:\n",
    "    ensemble_models[name] = optimized_linear_models[name]  # ✅ Use Optuna-optimized models\n",
    "\n",
    "# Add top 1 boosting model from Optuna optimization\n",
    "boosting_name = list(top_boosting_models.keys())[0]\n",
    "ensemble_models[boosting_name] = optimized_models[boosting_name]  # ✅ Use Optuna-optimized models\n",
    "\n",
    "print(f\"\\n2. OPTUNA-ENHANCED ENSEMBLE COMPOSITION\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Selected {len(ensemble_models)} Optuna-optimized models for ensemble:\")\n",
    "for name in ensemble_models.keys():\n",
    "    print(f\"  ✅ {name} (Optuna-optimized)\")\n",
    "    \n",
    "print(f\"\\nTotal ensemble models: {len(ensemble_models)}\")\n",
    "\n",
    "# Store performance metrics for weight calculation using Optuna results\n",
    "model_performance = {}\n",
    "for name in ensemble_models.keys():\n",
    "    if name in cv_results_linear_optimized:  # Linear model\n",
    "        model_performance[name] = {\n",
    "            'mae': cv_results_linear_optimized[name]['test_mae'],\n",
    "            'r2': cv_results_linear_optimized[name]['test_r2']\n",
    "        }\n",
    "    else:  # Boosting model\n",
    "        model_performance[name] = {\n",
    "            'mae': cv_results_optimized[name]['test_mae'], \n",
    "            'r2': cv_results_optimized[name]['test_r2']\n",
    "        }\n",
    "\n",
    "print(f\"\\n3. OPTUNA-OPTIMIZED MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"-\" * 50)\n",
    "for name, perf in model_performance.items():\n",
    "    print(f\"{name}: MAE = {perf['mae']:.4f}, R² = {perf['r2']:.4f}\")\n",
    "\n",
    "# Display the Optuna-optimized parameters being used\n",
    "print(f\"\\n4. OPTUNA PARAMETERS IN USE\")\n",
    "print(\"-\" * 50)\n",
    "for name in ensemble_models.keys():\n",
    "    if name in optimized_linear_params and optimized_linear_params[name]:\n",
    "        print(f\"\\n{name} (Linear):\")\n",
    "        for param, value in optimized_linear_params[name].items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {param}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {param}: {value}\")\n",
    "    elif name in optimized_params:\n",
    "        print(f\"\\n{name} (Boosting):\")\n",
    "        for param, value in optimized_params[name].items():\n",
    "            if isinstance(value, float) and 'rate' in param:\n",
    "                print(f\"  {param}: {value:.4f}\")\n",
    "            elif isinstance(value, (int, bool, str)):\n",
    "                print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\n🚀 Using Optuna-optimized models for superior ensemble performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9e2121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. GENERATING OUT-OF-FOLD PREDICTIONS (OPTUNA MODELS)\n",
      "------------------------------------------------------------\n",
      "Generating OOF predictions for Lasso (Optuna-optimized)...\n",
      "  OOF MAE: 2.7235\n",
      "Generating OOF predictions for ElasticNet (Optuna-optimized)...\n",
      "  OOF MAE: 2.7260\n",
      "Generating OOF predictions for CatBoost (Optuna-optimized)...\n",
      "  OOF MAE: 3.0335\n",
      "\n",
      "OOF prediction matrix shape: (1812, 3)\n",
      "\n",
      "6. OPTIMIZING ENSEMBLE WEIGHTS FOR OPTUNA MODELS\n",
      "------------------------------------------------------------\n",
      "Initial weights (based on Optuna-optimized model performance):\n",
      "  Lasso: 0.344\n",
      "  ElasticNet: 0.344\n",
      "  CatBoost: 0.312\n",
      "\n",
      "Optimization successful: True\n",
      "Optimal Optuna ensemble OOF MAE: 2.7227\n",
      "\n",
      "Optimal weights for Optuna-optimized models:\n",
      "  Lasso: 0.942\n",
      "  ElasticNet: 0.000\n",
      "  CatBoost: 0.058\n",
      "\n",
      "Improvement over best individual Optuna model:\n",
      "  Best individual MAE: 2.7235\n",
      "  Ensemble MAE: 2.7227\n",
      "  Improvement: 0.0008 (0.03%)\n",
      "\n",
      "✨ Ensemble optimization complete using Optuna-optimized base models!\n"
     ]
    }
   ],
   "source": [
    "# Generate out-of-fold predictions for weight optimization with Optuna-optimized models\n",
    "print(\"\\n5. GENERATING OUT-OF-FOLD PREDICTIONS (OPTUNA MODELS)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Generate OOF predictions for each Optuna-optimized model\n",
    "oof_predictions = {}\n",
    "model_names = list(ensemble_models.keys())\n",
    "\n",
    "# Use the same CV strategy as the original optimization\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in ensemble_models.items():\n",
    "    print(f\"Generating OOF predictions for {name} (Optuna-optimized)...\")\n",
    "    \n",
    "    # Use the same CV strategy as before\n",
    "    oof_pred = cross_val_predict(model, X_full, y_full, cv=cv, method='predict')\n",
    "    oof_predictions[name] = oof_pred\n",
    "    \n",
    "    # Calculate OOF MAE\n",
    "    oof_mae = mean_absolute_error(y_full, oof_pred)\n",
    "    print(f\"  OOF MAE: {oof_mae:.4f}\")\n",
    "\n",
    "# Create OOF prediction matrix\n",
    "oof_matrix = np.column_stack([oof_predictions[name] for name in model_names])\n",
    "print(f\"\\nOOF prediction matrix shape: {oof_matrix.shape}\")\n",
    "\n",
    "print(\"\\n6. OPTIMIZING ENSEMBLE WEIGHTS FOR OPTUNA MODELS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def ensemble_mae_objective(weights, predictions, targets):\n",
    "    \"\"\"Objective function to minimize: weighted ensemble MAE\"\"\"\n",
    "    weights = np.array(weights)\n",
    "    weights = weights / weights.sum()  # Normalize to sum to 1\n",
    "    ensemble_pred = np.dot(predictions, weights)\n",
    "    return mean_absolute_error(targets, ensemble_pred)\n",
    "\n",
    "# Initial weights based on inverse MAE (better models get higher weights)\n",
    "initial_weights = []\n",
    "for name in model_names:\n",
    "    mae = model_performance[name]['mae']\n",
    "    # Inverse weight: lower MAE = higher weight\n",
    "    weight = 1.0 / mae if mae > 0 else 1.0\n",
    "    initial_weights.append(weight)\n",
    "\n",
    "# Normalize initial weights\n",
    "initial_weights = np.array(initial_weights)\n",
    "initial_weights = initial_weights / initial_weights.sum()\n",
    "\n",
    "print(\"Initial weights (based on Optuna-optimized model performance):\")\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f\"  {name}: {initial_weights[i]:.3f}\")\n",
    "\n",
    "# Constraint: weights must sum to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0})\n",
    "\n",
    "# Bounds: each weight between 0 and 1\n",
    "bounds = [(0.0, 1.0) for _ in range(len(model_names))]\n",
    "\n",
    "# Optimize weights\n",
    "result = minimize(\n",
    "    ensemble_mae_objective,\n",
    "    initial_weights,\n",
    "    args=(oof_matrix, y_full),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "optimal_weights = result.x\n",
    "optimal_mae = result.fun\n",
    "\n",
    "print(f\"\\nOptimization successful: {result.success}\")\n",
    "print(f\"Optimal Optuna ensemble OOF MAE: {optimal_mae:.4f}\")\n",
    "print(\"\\nOptimal weights for Optuna-optimized models:\")\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f\"  {name}: {optimal_weights[i]:.3f}\")\n",
    "\n",
    "# Calculate improvement over best individual Optuna-optimized model\n",
    "best_individual_mae = min([model_performance[name]['mae'] for name in model_names])\n",
    "improvement = best_individual_mae - optimal_mae\n",
    "print(f\"\\nImprovement over best individual Optuna model:\")\n",
    "print(f\"  Best individual MAE: {best_individual_mae:.4f}\")\n",
    "print(f\"  Ensemble MAE: {optimal_mae:.4f}\")\n",
    "print(f\"  Improvement: {improvement:.4f} ({improvement/best_individual_mae*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n✨ Ensemble optimization complete using Optuna-optimized base models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5ad7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. TRAINING FINAL OPTUNA-OPTIMIZED ENSEMBLE MODELS\n",
      "------------------------------------------------------------\n",
      "Training Lasso (Optuna-optimized) on full dataset...\n",
      "  Test predictions range: 44.85 to 109.50\n",
      "Training ElasticNet (Optuna-optimized) on full dataset...\n",
      "  Test predictions range: 44.79 to 109.02\n",
      "Training CatBoost (Optuna-optimized) on full dataset...\n",
      "  Test predictions range: 47.63 to 102.66\n",
      "\n",
      "All 3 Optuna-optimized models trained successfully!\n",
      "Test prediction matrix shape: (453, 3)\n",
      "\n",
      "8. GENERATING OPTUNA-ENHANCED ENSEMBLE PREDICTIONS\n",
      "------------------------------------------------------------\n",
      "Optuna-enhanced ensemble test predictions:\n",
      "  Range: 45.02 to 109.10\n",
      "  Mean: 79.08\n",
      "  Std: 12.04\n",
      "\n",
      "Comparison with individual Optuna-optimized models:\n",
      "  Lasso (weight=0.942): mean=79.08, std=12.05\n",
      "  ElasticNet (weight=0.000): mean=79.09, std=12.02\n",
      "  CatBoost (weight=0.058): mean=79.05, std=11.99\n",
      "\n",
      "9. CREATING OPTUNA-ENHANCED SUBMISSION FILE\n",
      "------------------------------------------------------------\n",
      "✅ Optuna-enhanced submission saved: submission_optuna_weighted_ensemble_20251004_175738.csv\n",
      "📁 Path: /home/chrisfkh/sctp-ds-ai/mod3/kaggle_moneyball/submissions/submission_optuna_weighted_ensemble_20251004_175738.csv\n",
      "📊 Predictions shape: (453, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "     ID          W\n",
      "0  1756  69.395102\n",
      "1  1282  74.330236\n",
      "2   351  84.269197\n",
      "3   421  87.164883\n",
      "4    57  93.236723\n",
      "5  1557  97.447407\n",
      "6   846  79.196359\n",
      "7  1658  84.180891\n",
      "8   112  72.936905\n",
      "9  2075  83.672770\n",
      "\n",
      "10. OPTUNA-ENHANCED WEIGHTED ENSEMBLE SUMMARY\n",
      "------------------------------------------------------------\n",
      "Ensemble Composition (Optuna-optimized models):\n",
      "  Lasso: 94.2%\n",
      "  ElasticNet: 0.0%\n",
      "  CatBoost: 5.8%\n",
      "\n",
      "Expected Performance:\n",
      "  Cross-validation MAE: 2.7227\n",
      "  Expected Kaggle score: ~2.72\n",
      "  Improvement vs best individual Optuna model: 0.0008\n",
      "\n",
      "🚀 Phase 1 complete with Optuna-optimized models!\n"
     ]
    }
   ],
   "source": [
    "# Train final Optuna-optimized models and generate test predictions\n",
    "print(\"\\n7. TRAINING FINAL OPTUNA-OPTIMIZED ENSEMBLE MODELS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Train each Optuna-optimized model on the full training dataset\n",
    "final_models = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for name, model in ensemble_models.items():\n",
    "    print(f\"Training {name} (Optuna-optimized) on full dataset...\")\n",
    "    \n",
    "    # Clone and train the Optuna-optimized model\n",
    "    final_model = model  # Already configured with Optuna parameters\n",
    "    final_model.fit(X_full, y_full)\n",
    "    final_models[name] = final_model\n",
    "    \n",
    "    # Generate test predictions\n",
    "    test_pred = final_model.predict(X_test_final)\n",
    "    test_predictions[name] = test_pred\n",
    "    \n",
    "    print(f\"  Test predictions range: {test_pred.min():.2f} to {test_pred.max():.2f}\")\n",
    "\n",
    "print(f\"\\nAll {len(final_models)} Optuna-optimized models trained successfully!\")\n",
    "\n",
    "# Create test prediction matrix\n",
    "test_matrix = np.column_stack([test_predictions[name] for name in model_names])\n",
    "print(f\"Test prediction matrix shape: {test_matrix.shape}\")\n",
    "\n",
    "print(\"\\n8. GENERATING OPTUNA-ENHANCED ENSEMBLE PREDICTIONS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Generate weighted ensemble predictions using Optuna-optimized models\n",
    "ensemble_test_pred = np.dot(test_matrix, optimal_weights)\n",
    "\n",
    "print(f\"Optuna-enhanced ensemble test predictions:\")\n",
    "print(f\"  Range: {ensemble_test_pred.min():.2f} to {ensemble_test_pred.max():.2f}\")\n",
    "print(f\"  Mean: {ensemble_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {ensemble_test_pred.std():.2f}\")\n",
    "\n",
    "# Compare with individual Optuna-optimized model predictions\n",
    "print(f\"\\nComparison with individual Optuna-optimized models:\")\n",
    "for i, name in enumerate(model_names):\n",
    "    individual_pred = test_predictions[name]\n",
    "    weight = optimal_weights[i]\n",
    "    print(f\"  {name} (weight={weight:.3f}): mean={individual_pred.mean():.2f}, std={individual_pred.std():.2f}\")\n",
    "\n",
    "print(f\"\\n9. CREATING OPTUNA-ENHANCED SUBMISSION FILE\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': test_df['ID'],  # Use the actual ID column from test.csv\n",
    "    'W': ensemble_test_pred\n",
    "})\n",
    "\n",
    "# Generate timestamp for unique filename\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "submission_filename = f\"submission_optuna_weighted_ensemble_{timestamp}.csv\"\n",
    "submission_path = SUB_DIR / submission_filename\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"✅ Optuna-enhanced submission saved: {submission_filename}\")\n",
    "print(f\"📁 Path: {submission_path}\")\n",
    "print(f\"📊 Predictions shape: {submission_df.shape}\")\n",
    "\n",
    "# Display first few predictions\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(f\"\\n10. OPTUNA-ENHANCED WEIGHTED ENSEMBLE SUMMARY\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Ensemble Composition (Optuna-optimized models):\")\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f\"  {name}: {optimal_weights[i]:.1%}\")\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  Cross-validation MAE: {optimal_mae:.4f}\")\n",
    "print(f\"  Expected Kaggle score: ~{optimal_mae:.2f}\")\n",
    "print(f\"  Improvement vs best individual Optuna model: {improvement:.4f}\")\n",
    "print(f\"\\n🚀 Phase 1 complete with Optuna-optimized models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889453b4",
   "metadata": {},
   "source": [
    "# Stacked Ensemble Implementation\n",
    "\n",
    "The weighted ensemble scored 3.04775 on Kaggle vs 2.7190 CV, indicating distribution mismatch between CV and test set. \n",
    "\n",
    "## Stacking Strategy:\n",
    "- **Expand base models**: Include more diverse models (XGBoost, LightGBM, different regularization strengths)\n",
    "- **Two-level stacking**: Level 1 base models → Level 2 meta-learner \n",
    "- **Robust meta-learner**: Use Ridge regression to combine predictions and learn complex relationships\n",
    "- **Better generalization**: Out-of-fold training prevents overfitting to specific data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc6aaa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACKED ENSEMBLE IMPLEMENTATION (OPTUNA-OPTIMIZED)\n",
      "============================================================\n",
      "\n",
      "1. CREATING DIVERSE OPTUNA-OPTIMIZED BASE MODELS\n",
      "------------------------------------------------------------\n",
      "Base models for stacking (Optuna-optimized): 11\n",
      "  ✅ Ridge_optuna\n",
      "  ✅ Ridge_conservative\n",
      "  ✅ Ridge_aggressive\n",
      "  ✅ Lasso_optuna\n",
      "  ✅ Lasso_variation\n",
      "  ✅ ElasticNet_optuna\n",
      "  ✅ XGBoost_optuna\n",
      "  ✅ XGBoost_conservative\n",
      "  ✅ CatBoost_optuna\n",
      "  ✅ Best_Linear\n",
      "  ✅ Best_Boosting\n",
      "\n",
      "2. IMPLEMENTING STACKED ENSEMBLE WITH OPTUNA MODELS\n",
      "------------------------------------------------------------\n",
      "Generating Level 1 out-of-fold predictions with Optuna-optimized models...\n",
      "  Processing Ridge_optuna (Optuna-enhanced)...\n",
      "    OOF MAE: 2.7264\n",
      "  Processing Ridge_conservative (Optuna-enhanced)...\n",
      "    OOF MAE: 2.7530\n",
      "  Processing Ridge_aggressive (Optuna-enhanced)...\n",
      "    OOF MAE: 2.7301\n",
      "  Processing Lasso_optuna (Optuna-enhanced)...\n",
      "    OOF MAE: 2.7237\n",
      "  Processing Lasso_variation (Optuna-enhanced)...\n",
      "    OOF MAE: 2.7316\n",
      "  Processing ElasticNet_optuna (Optuna-enhanced)...\n",
      "    OOF MAE: 2.7262\n",
      "  Processing XGBoost_optuna (Optuna-enhanced)...\n",
      "    OOF MAE: 3.0556\n",
      "  Processing XGBoost_conservative (Optuna-enhanced)...\n",
      "    OOF MAE: 3.0939\n",
      "  Processing CatBoost_optuna (Optuna-enhanced)...\n",
      "    OOF MAE: 3.0349\n",
      "  Processing Best_Linear (Optuna-enhanced)...\n",
      "    OOF MAE: 2.7235\n",
      "  Processing Best_Boosting (Optuna-enhanced)...\n",
      "    OOF MAE: 3.0335\n",
      "\n",
      "Level 1 OOF predictions shape: (1812, 11)\n",
      "Level 1 test predictions shape: (453, 11)\n",
      "🚀 All base models use Optuna-optimized parameters!\n"
     ]
    }
   ],
   "source": [
    "print(\"STACKED ENSEMBLE IMPLEMENTATION (OPTUNA-OPTIMIZED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"\\n1. CREATING DIVERSE OPTUNA-OPTIMIZED BASE MODELS\") \n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create diverse base models using Optuna-optimized parameters for better generalization\n",
    "def create_optuna_linear_model(model_type, params, suffix=\"\"):\n",
    "    \"\"\"Create linear model with Optuna-optimized parameters\"\"\"\n",
    "    if model_type == 'Ridge':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Ridge(alpha=params.get('alpha', 1.0), random_state=42))\n",
    "        ])\n",
    "    elif model_type == 'Lasso':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', Lasso(\n",
    "                alpha=params.get('alpha', 0.01), \n",
    "                max_iter=params.get('max_iter', 10000),\n",
    "                tol=1e-3,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "    elif model_type == 'ElasticNet':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', ElasticNet(\n",
    "                alpha=params.get('alpha', 0.1),\n",
    "                l1_ratio=params.get('l1_ratio', 0.5),\n",
    "                max_iter=params.get('max_iter', 10000),\n",
    "                tol=1e-3,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "# Build stacking models using Optuna-optimized parameters\n",
    "stacking_models = {}\n",
    "\n",
    "# Linear models with Optuna-optimized parameters + variations for diversity\n",
    "if 'Ridge' in optimized_linear_params:\n",
    "    ridge_params = optimized_linear_params['Ridge']\n",
    "    # Use optimized alpha and create variations\n",
    "    base_alpha = ridge_params.get('alpha', 1.0)\n",
    "    stacking_models['Ridge_optuna'] = create_optuna_linear_model('Ridge', ridge_params)\n",
    "    stacking_models['Ridge_conservative'] = create_optuna_linear_model('Ridge', {'alpha': base_alpha * 5})\n",
    "    stacking_models['Ridge_aggressive'] = create_optuna_linear_model('Ridge', {'alpha': base_alpha * 0.2})\n",
    "\n",
    "if 'Lasso' in optimized_linear_params:\n",
    "    lasso_params = optimized_linear_params['Lasso']\n",
    "    stacking_models['Lasso_optuna'] = create_optuna_linear_model('Lasso', lasso_params)\n",
    "    # Create variation\n",
    "    base_alpha = lasso_params.get('alpha', 0.01)\n",
    "    stacking_models['Lasso_variation'] = create_optuna_linear_model('Lasso', {\n",
    "        'alpha': base_alpha * 2,\n",
    "        'max_iter': lasso_params.get('max_iter', 10000)\n",
    "    })\n",
    "\n",
    "if 'ElasticNet' in optimized_linear_params:\n",
    "    elasticnet_params = optimized_linear_params['ElasticNet']\n",
    "    stacking_models['ElasticNet_optuna'] = create_optuna_linear_model('ElasticNet', elasticnet_params)\n",
    "\n",
    "# Tree-based models with Optuna-optimized parameters\n",
    "if 'XGBoost' in optimized_params:\n",
    "    xgb_params = optimized_params['XGBoost'].copy()\n",
    "    # Use Optuna parameters but make conservative for stacking\n",
    "    xgb_params['n_estimators'] = min(xgb_params.get('n_estimators', 150), 150)  # Cap for speed\n",
    "    xgb_params['verbosity'] = 0\n",
    "    xgb_params['random_state'] = 42\n",
    "    \n",
    "    # Create XGBoost with Optuna parameters\n",
    "    stacking_models['XGBoost_optuna'] = XGBRegressor(**xgb_params)\n",
    "    \n",
    "    # Create conservative variation\n",
    "    conservative_params = xgb_params.copy()\n",
    "    conservative_params['max_depth'] = max(3, xgb_params.get('max_depth', 6) - 1)  # Shallower\n",
    "    conservative_params['learning_rate'] = xgb_params.get('learning_rate', 0.1) * 0.8  # Slower\n",
    "    stacking_models['XGBoost_conservative'] = XGBRegressor(**conservative_params)\n",
    "\n",
    "if 'CatBoost' in optimized_params:\n",
    "    cat_params = optimized_params['CatBoost'].copy()\n",
    "    # Use Optuna parameters but make conservative for stacking\n",
    "    cat_params['iterations'] = min(cat_params.get('iterations', 150), 150)  # Cap for speed\n",
    "    cat_params['verbose'] = False\n",
    "    cat_params['random_seed'] = 42\n",
    "    \n",
    "    stacking_models['CatBoost_optuna'] = CatBoostRegressor(**cat_params)\n",
    "\n",
    "# Add the best individual Optuna-optimized models\n",
    "stacking_models['Best_Linear'] = best_linear_model  # From Optuna optimization\n",
    "stacking_models['Best_Boosting'] = best_model       # From Optuna optimization\n",
    "\n",
    "print(f\"Base models for stacking (Optuna-optimized): {len(stacking_models)}\")\n",
    "for name in stacking_models.keys():\n",
    "    print(f\"  ✅ {name}\")\n",
    "\n",
    "print(f\"\\n2. IMPLEMENTING STACKED ENSEMBLE WITH OPTUNA MODELS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Use the same CV folds for all models to ensure consistency  \n",
    "stacking_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Level 1: Generate out-of-fold predictions from Optuna-optimized base models\n",
    "print(\"Generating Level 1 out-of-fold predictions with Optuna-optimized models...\")\n",
    "\n",
    "level1_oof_preds = np.zeros((len(X_full), len(stacking_models)))\n",
    "level1_test_preds = np.zeros((len(X_test_final), len(stacking_models)))\n",
    "\n",
    "model_names_stack = list(stacking_models.keys())\n",
    "\n",
    "for i, (name, model) in enumerate(stacking_models.items()):\n",
    "    print(f\"  Processing {name} (Optuna-enhanced)...\")\n",
    "    \n",
    "    # Generate OOF predictions\n",
    "    oof_pred = cross_val_predict(model, X_full, y_full, cv=stacking_cv, method='predict')\n",
    "    level1_oof_preds[:, i] = oof_pred\n",
    "    \n",
    "    # Train on full dataset and predict test set\n",
    "    model_clone = clone(model)\n",
    "    model_clone.fit(X_full, y_full)\n",
    "    test_pred = model_clone.predict(X_test_final)\n",
    "    level1_test_preds[:, i] = test_pred\n",
    "    \n",
    "    # Calculate individual model OOF MAE\n",
    "    oof_mae = mean_absolute_error(y_full, oof_pred)\n",
    "    print(f\"    OOF MAE: {oof_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nLevel 1 OOF predictions shape: {level1_oof_preds.shape}\")\n",
    "print(f\"Level 1 test predictions shape: {level1_test_preds.shape}\")\n",
    "print(f\"🚀 All base models use Optuna-optimized parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54168822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. TRAINING LEVEL 2 META-LEARNER (OPTUNA-ENHANCED)\n",
      "------------------------------------------------------------\n",
      "Evaluating Optuna-enhanced meta-learners:\n",
      "  🚀 Ridge_meta_optuna: MAE = 2.7261 (±0.0507)\n",
      "  📊 Ridge_meta_conservative: MAE = 2.7278 (±0.0497)\n",
      "  📊 Ridge_meta_aggressive: MAE = 2.7249 (±0.0494)\n",
      "  🚀 Lasso_meta_optuna: MAE = 2.7270 (±0.0492)\n",
      "  🚀 ElasticNet_meta_optuna: MAE = 2.7278 (±0.0500)\n",
      "  📊 Ridge_meta_standard: MAE = 2.7250 (±0.0499)\n",
      "  📊 LinearRegression_meta: MAE = 2.7249 (±0.0487)\n",
      "\n",
      "🏆 Best meta-learner: Ridge_meta_aggressive\n",
      "Best meta-learner CV MAE: 2.7249\n",
      "Uses Optuna optimization: ❌ No\n",
      "\n",
      "4. TRAINING FINAL OPTUNA-ENHANCED STACKED MODEL\n",
      "------------------------------------------------------------\n",
      "Optuna-enhanced stacked ensemble test predictions:\n",
      "  Range: 45.14 to 109.22\n",
      "  Mean: 78.98\n",
      "  Std: 12.05\n",
      "\n",
      "5. COMPARISON WITH PHASE 1 OPTUNA ENSEMBLE\n",
      "------------------------------------------------------------\n",
      "Phase 1 Optuna ensemble predictions:\n",
      "  Range: 45.02 to 109.10\n",
      "  Mean: 79.08\n",
      "  Std: 12.04\n",
      "\n",
      "Phase 2 Optuna stacked predictions:\n",
      "  Range: 45.14 to 109.22\n",
      "  Mean: 78.98\n",
      "  Std: 12.05\n",
      "\n",
      "Correlation between Phase 1 and Phase 2 Optuna ensembles: 0.9999\n",
      "\n",
      "Phase 2 (Optuna-enhanced stacked ensemble):\n",
      "  CV MAE: 2.7249\n",
      "  Expected improvement vs Phase 1: -0.0022\n",
      "  ⚠️ Phase 2 CV did not improve Phase 1\n",
      "  📊 Both benefit from Optuna optimization\n",
      "\n",
      "🎯 Both ensembles now use Optuna-optimized models!\n"
     ]
    }
   ],
   "source": [
    "# Level 2: Train meta-learner with Optuna-enhanced parameters\n",
    "print(f\"\\n3. TRAINING LEVEL 2 META-LEARNER (OPTUNA-ENHANCED)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use Optuna-optimized parameters for meta-learners too\n",
    "meta_learners = {}\n",
    "\n",
    "# Create meta-learners using Optuna-optimized parameters when available\n",
    "if 'Ridge' in optimized_linear_params:\n",
    "    ridge_alpha = optimized_linear_params['Ridge'].get('alpha', 1.0)\n",
    "    meta_learners['Ridge_meta_optuna'] = Ridge(alpha=ridge_alpha)\n",
    "    meta_learners['Ridge_meta_conservative'] = Ridge(alpha=ridge_alpha * 10)  # More regularized\n",
    "    meta_learners['Ridge_meta_aggressive'] = Ridge(alpha=ridge_alpha * 0.1)   # Less regularized\n",
    "\n",
    "if 'Lasso' in optimized_linear_params:\n",
    "    lasso_alpha = optimized_linear_params['Lasso'].get('alpha', 0.01)\n",
    "    lasso_max_iter = optimized_linear_params['Lasso'].get('max_iter', 10000)\n",
    "    meta_learners['Lasso_meta_optuna'] = Lasso(alpha=lasso_alpha, max_iter=lasso_max_iter, tol=1e-3)\n",
    "\n",
    "if 'ElasticNet' in optimized_linear_params:\n",
    "    en_alpha = optimized_linear_params['ElasticNet'].get('alpha', 0.1)\n",
    "    en_l1_ratio = optimized_linear_params['ElasticNet'].get('l1_ratio', 0.5)\n",
    "    en_max_iter = optimized_linear_params['ElasticNet'].get('max_iter', 10000)\n",
    "    meta_learners['ElasticNet_meta_optuna'] = ElasticNet(\n",
    "        alpha=en_alpha, l1_ratio=en_l1_ratio, max_iter=en_max_iter, tol=1e-3\n",
    "    )\n",
    "\n",
    "# Add some standard options for comparison\n",
    "meta_learners['Ridge_meta_standard'] = Ridge(alpha=1.0)\n",
    "meta_learners['LinearRegression_meta'] = LinearRegression()\n",
    "\n",
    "best_meta_mae = float('inf')\n",
    "best_meta_name = None\n",
    "best_meta_model = None\n",
    "\n",
    "print(\"Evaluating Optuna-enhanced meta-learners:\")\n",
    "for name, meta_model in meta_learners.items():\n",
    "    # Cross-validate the meta-learner on OOF predictions\n",
    "    meta_cv_scores = cross_val_score(\n",
    "        meta_model, level1_oof_preds, y_full,\n",
    "        cv=5, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "    meta_mae = -meta_cv_scores.mean()\n",
    "    meta_mae_std = meta_cv_scores.std()\n",
    "    \n",
    "    optuna_flag = \"🚀\" if \"optuna\" in name else \"📊\"\n",
    "    print(f\"  {optuna_flag} {name}: MAE = {meta_mae:.4f} (±{meta_mae_std:.4f})\")\n",
    "    \n",
    "    if meta_mae < best_meta_mae:\n",
    "        best_meta_mae = meta_mae\n",
    "        best_meta_name = name\n",
    "        best_meta_model = meta_model\n",
    "\n",
    "print(f\"\\n🏆 Best meta-learner: {best_meta_name}\")\n",
    "print(f\"Best meta-learner CV MAE: {best_meta_mae:.4f}\")\n",
    "is_optuna_meta = \"optuna\" in best_meta_name\n",
    "print(f\"Uses Optuna optimization: {'✅ Yes' if is_optuna_meta else '❌ No'}\")\n",
    "\n",
    "# Train the best meta-learner on all OOF predictions\n",
    "print(f\"\\n4. TRAINING FINAL OPTUNA-ENHANCED STACKED MODEL\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "final_meta_model = clone(best_meta_model)\n",
    "final_meta_model.fit(level1_oof_preds, y_full)\n",
    "\n",
    "# Generate final stacked predictions\n",
    "stacked_test_pred = final_meta_model.predict(level1_test_preds)\n",
    "\n",
    "print(f\"Optuna-enhanced stacked ensemble test predictions:\")\n",
    "print(f\"  Range: {stacked_test_pred.min():.2f} to {stacked_test_pred.max():.2f}\")\n",
    "print(f\"  Mean: {stacked_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {stacked_test_pred.std():.2f}\")\n",
    "\n",
    "# Compare with Phase 1 Optuna ensemble\n",
    "print(f\"\\n5. COMPARISON WITH PHASE 1 OPTUNA ENSEMBLE\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Phase 1 Optuna ensemble predictions:\")\n",
    "print(f\"  Range: {ensemble_test_pred.min():.2f} to {ensemble_test_pred.max():.2f}\")\n",
    "print(f\"  Mean: {ensemble_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {ensemble_test_pred.std():.2f}\")\n",
    "\n",
    "print(f\"\\nPhase 2 Optuna stacked predictions:\")\n",
    "print(f\"  Range: {stacked_test_pred.min():.2f} to {stacked_test_pred.max():.2f}\")  \n",
    "print(f\"  Mean: {stacked_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {stacked_test_pred.std():.2f}\")\n",
    "\n",
    "# Calculate correlation between Phase 1 and Phase 2 predictions\n",
    "correlation = np.corrcoef(ensemble_test_pred, stacked_test_pred)[0, 1]\n",
    "print(f\"\\nCorrelation between Phase 1 and Phase 2 Optuna ensembles: {correlation:.4f}\")\n",
    "\n",
    "print(f\"\\nPhase 2 (Optuna-enhanced stacked ensemble):\")\n",
    "print(f\"  CV MAE: {best_meta_mae:.4f}\")\n",
    "improvement_vs_phase1 = optimal_mae - best_meta_mae\n",
    "print(f\"  Expected improvement vs Phase 1: {improvement_vs_phase1:.4f}\")\n",
    "\n",
    "if best_meta_mae < optimal_mae:\n",
    "    print(f\"  ✅ Phase 2 shows improvement over Phase 1!\")\n",
    "    print(f\"  🚀 Optuna optimization helped both phases!\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Phase 2 CV did not improve Phase 1\")\n",
    "    print(f\"  📊 Both benefit from Optuna optimization\")\n",
    "    \n",
    "print(f\"\\n🎯 Both ensembles now use Optuna-optimized models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cb2464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. CREATING OPTUNA-ENHANCED STACKED ENSEMBLE SUBMISSION\n",
      "----------------------------------------------------------------------\n",
      "✅ Optuna-enhanced stacked ensemble submission saved: submission_optuna_stacked_ensemble_20251004_175745.csv\n",
      "📁 Path: /home/chrisfkh/sctp-ds-ai/mod3/kaggle_moneyball/submissions/submission_optuna_stacked_ensemble_20251004_175745.csv\n",
      "📊 Predictions shape: (453, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "     ID          W\n",
      "0  1756  69.308268\n",
      "1  1282  74.262842\n",
      "2   351  84.004631\n",
      "3   421  86.935768\n",
      "4    57  93.134654\n",
      "5  1557  97.653192\n",
      "6   846  79.067162\n",
      "7  1658  83.891992\n",
      "8   112  72.631289\n",
      "9  2075  83.511754\n",
      "\n",
      "7. OPTUNA-ENHANCED STACKED ENSEMBLE SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "Base Models (all Optuna-optimized): 11\n",
      "  🚀 Ridge_optuna\n",
      "  📊 Ridge_conservative\n",
      "  📊 Ridge_aggressive\n",
      "  🚀 Lasso_optuna\n",
      "  📊 Lasso_variation\n",
      "  🚀 ElasticNet_optuna\n",
      "  🚀 XGBoost_optuna\n",
      "  📊 XGBoost_conservative\n",
      "  🚀 CatBoost_optuna\n",
      "  🚀 Best_Linear\n",
      "  🚀 Best_Boosting\n",
      "\n",
      "Meta-learner: Ridge_meta_aggressive\n",
      "Meta-learner status: 📊 Standard parameters\n",
      "\n",
      "Expected Performance:\n",
      "  CV MAE: 2.7249\n",
      "  Expected Kaggle improvement vs Phase 1: -0.0022\n",
      "\n",
      "🎯 PHASE COMPARISON SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "Phase 1 (Weighted): MAE = 2.7227 | Correlation: 1.000\n",
      "Phase 2 (Stacked):  MAE = 2.7249 | Improvement: -0.0022\n",
      "🏆 Current leader: Phase 1 (Weighted)\n",
      "\n",
      "✨ Both phases now leverage full Optuna optimization!\n",
      "🚀 Ready to submit the best performing ensemble to Kaggle!\n",
      "\n",
      "📈 OPTIMIZATION JOURNEY\n",
      "----------------------------------------------------------------------\n",
      "1. ✅ Boosting models optimized with Optuna\n",
      "2. ✅ Linear models optimized with Optuna\n",
      "3. ✅ Phase 1 ensemble uses Optuna models\n",
      "4. ✅ Phase 2 ensemble uses Optuna models + meta-learner\n",
      "5. 🎯 Ready for Kaggle submission with optimized ensembles!\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna-enhanced stacked ensemble submission\n",
    "print(f\"\\n6. CREATING OPTUNA-ENHANCED STACKED ENSEMBLE SUBMISSION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create submission DataFrame for Optuna-enhanced stacked ensemble\n",
    "stacked_submission_df = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'W': stacked_test_pred\n",
    "})\n",
    "\n",
    "# Generate timestamp\n",
    "timestamp_stacked = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "stacked_submission_filename = f\"submission_optuna_stacked_ensemble_{timestamp_stacked}.csv\"\n",
    "stacked_submission_path = SUB_DIR / stacked_submission_filename\n",
    "\n",
    "# Save submission\n",
    "stacked_submission_df.to_csv(stacked_submission_path, index=False)\n",
    "\n",
    "print(f\"✅ Optuna-enhanced stacked ensemble submission saved: {stacked_submission_filename}\")\n",
    "print(f\"📁 Path: {stacked_submission_path}\")\n",
    "print(f\"📊 Predictions shape: {stacked_submission_df.shape}\")\n",
    "\n",
    "# Display first few predictions\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(stacked_submission_df.head(10))\n",
    "\n",
    "# Final comprehensive summary\n",
    "print(f\"\\n7. OPTUNA-ENHANCED STACKED ENSEMBLE SUMMARY\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Base Models (all Optuna-optimized): {len(stacking_models)}\")\n",
    "for name in model_names_stack:\n",
    "    optuna_flag = \"🚀\" if any(x in name.lower() for x in ['optuna', 'best']) else \"📊\"\n",
    "    print(f\"  {optuna_flag} {name}\")\n",
    "\n",
    "print(f\"\\nMeta-learner: {best_meta_name}\")\n",
    "meta_optuna_status = \"🚀 Uses Optuna optimization\" if \"optuna\" in best_meta_name else \"📊 Standard parameters\"\n",
    "print(f\"Meta-learner status: {meta_optuna_status}\")\n",
    "\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  CV MAE: {best_meta_mae:.4f}\")\n",
    "print(f\"  Expected Kaggle improvement vs Phase 1: {improvement_vs_phase1:.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 PHASE COMPARISON SUMMARY\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Phase 1 (Weighted): MAE = {optimal_mae:.4f} | Correlation: {correlation:.3f}\")\n",
    "print(f\"Phase 2 (Stacked):  MAE = {best_meta_mae:.4f} | Improvement: {improvement_vs_phase1:.4f}\")\n",
    "\n",
    "winner = \"Phase 2 (Stacked)\" if best_meta_mae < optimal_mae else \"Phase 1 (Weighted)\"\n",
    "print(f\"🏆 Current leader: {winner}\")\n",
    "\n",
    "print(f\"\\n✨ Both phases now leverage full Optuna optimization!\")\n",
    "print(f\"🚀 Ready to submit the best performing ensemble to Kaggle!\")\n",
    "\n",
    "# Show the optimization journey\n",
    "print(f\"\\n📈 OPTIMIZATION JOURNEY\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"1. ✅ Boosting models optimized with Optuna\")\n",
    "print(f\"2. ✅ Linear models optimized with Optuna\")  \n",
    "print(f\"3. ✅ Phase 1 ensemble uses Optuna models\")\n",
    "print(f\"4. ✅ Phase 2 ensemble uses Optuna models + meta-learner\")\n",
    "print(f\"5. 🎯 Ready for Kaggle submission with optimized ensembles!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

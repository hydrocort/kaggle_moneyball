{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starter Code for Building Baseball Win Prediction Model\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Build robust path to data folder (notebooks and data are siblings)\n",
    "DATA_DIR = Path.cwd().parent / 'data'\n",
    "train_path = DATA_DIR / 'train.csv'\n",
    "test_path = DATA_DIR / 'test.csv'\n",
    "\n",
    "\n",
    "# Load the pre-processed train and test datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "\n",
    "\n",
    "# Select only the default features from DATA_DESCRIPTION.md\n",
    "default_features = [\n",
    "    # Basic Statistics\n",
    "    'G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'CS', 'HBP', 'SF',\n",
    "    'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA',\n",
    "    'E', 'DP', 'FP', 'attendance', 'BPF', 'PPF',\n",
    "    \n",
    "    # Derived Features\n",
    "    'R_per_game', 'RA_per_game', 'mlb_rpg',\n",
    "    \n",
    "    # Era Indicators\n",
    "    'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8',\n",
    "    \n",
    "    # Decade Indicators\n",
    "    'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950',\n",
    "    'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010'\n",
    " ]\n",
    "\n",
    "\n",
    "# Filter features that exist in both datasets\n",
    "available_features = [col for col in default_features if col in train_df.columns and col in test_df.columns]\n",
    "print(f\"Number of available default features: {len(available_features)}\")\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_df[available_features]\n",
    "y_train = train_df['W']\n",
    "X_test = test_df[available_features]\n",
    "y_test = test_df['W']\n",
    "\n",
    "\n",
    "# Scale features\n",
    "# Identify columns to exclude from scaling (one-hot encoded and label columns)\n",
    "one_hot_cols = [col for col in X_train.columns if col.startswith(('era_', 'decade_'))]\n",
    "other_cols = [col for col in X_train.columns if col not in one_hot_cols]\n",
    "\n",
    "\n",
    "# Scale only non-one-hot features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[other_cols] = scaler.fit_transform(X_train[other_cols])\n",
    "X_test_scaled[other_cols] = scaler.transform(X_test[other_cols])\n",
    "\n",
    "\n",
    "# Linear Regression Model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_train_preds = lr.predict(X_train_scaled)\n",
    "lr_test_preds = lr.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluate Linear Regression\n",
    "lr_train_mae = mean_absolute_error(y_train, lr_train_preds)\n",
    "lr_test_mae = mean_absolute_error(y_test, lr_test_preds)\n",
    "lr_test_rmse = np.sqrt(mean_squared_error(y_test, lr_test_preds))\n",
    "lr_test_r2 = r2_score(y_test, lr_test_preds)\n",
    "\n",
    "\n",
    "print(f\"Linear Regression Performance:\")\n",
    "print(f\"  Training MAE: {lr_train_mae:.4f}\")\n",
    "print(f\"  Test MAE: {lr_test_mae:.4f}\")\n",
    "print(f\"  Test RMSE: {lr_test_rmse:.4f}\")\n",
    "print(f\"  Test RÂ²: {lr_test_r2:.4f}\")\n",
    "\n",
    "\n",
    "# Feature importance from Linear Regression\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lr.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "\n",
    "# Visualize actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, lr_test_preds, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Wins')\n",
    "plt.ylabel('Predicted Wins')\n",
    "plt.title('Linear Regression: Actual vs Predicted Wins')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# Add residual plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals = y_test - lr_test_preds\n",
    "plt.scatter(lr_test_preds, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Wins')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Linear Regression: Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "869c9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1812, 51)\n",
      "Test set shape: (453, 45)\n",
      "'W' column in train dataset: True\n",
      "'W' column in test dataset: False\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Build robust path to data folder (notebooks and data are siblings)\n",
    "DATA_DIR = Path.cwd().parent / 'data'\n",
    "SUB_DIR = Path.cwd().parent / 'submissions'\n",
    "train_path = DATA_DIR / 'train.csv'\n",
    "test_path = DATA_DIR / 'test.csv'\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)  # This is for final predictions (no 'W' column)\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"'W' column in train dataset: {'W' in train_df.columns}\")\n",
    "print(f\"'W' column in test dataset: {'W' in test_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "49d476af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created derived features: R_per_game, RA_per_game\n",
      "Train - R_per_game range: 2.409 to 6.884\n",
      "Train - RA_per_game range: 2.458 to 7.686\n",
      "Test - R_per_game range: 2.783 to 6.896\n",
      "Test - RA_per_game range: 2.867 to 6.865\n",
      "\n",
      "Created derived feature: Expected_Wins\n",
      "Train - Expected_Wins range: 35.860 to 119.963\n",
      "Test - Expected_Wins range: 40.352 to 107.111\n",
      "\n",
      "Created derived feature: Times_On_Base\n",
      "Train - Times_On_Base range: 1367.000 to 2415.000\n",
      "Test - Times_On_Base range: 1453.000 to 2327.000\n",
      "\n",
      "Created derived feature: BB_Rate\n",
      "Train - BB_Rate range: 0.051 to 0.136\n",
      "Test - BB_Rate range: 0.052 to 0.123\n",
      "\n",
      "Created derived feature: HR_Rate\n",
      "Train - HR_Rate range: 0.001 to 0.047\n",
      "Test - HR_Rate range: 0.001 to 0.045\n",
      "\n",
      "Created derived feature: OBP\n",
      "Train - OBP range: 0.262 to 0.382\n",
      "Test - OBP range: 0.267 to 0.382\n",
      "\n",
      "Created derived feature: SLG\n",
      "Train - SLG range: 0.274 to 0.491\n",
      "Test - SLG range: 0.261 to 0.488\n",
      "\n",
      "Created derived feature: OPS\n",
      "Train - OPS range: 0.539 to 0.870\n",
      "Test - OPS range: 0.530 to 0.870\n",
      "\n",
      "Created derived feature: Times_On_Base_Allowed\n",
      "Train - Times_On_Base_Allowed range: 1441.000 to 2536.000\n",
      "Test - Times_On_Base_Allowed range: 1454.000 to 2421.000\n",
      "\n",
      "Created derived feature: WHIP\n",
      "Train - WHIP range: 1.025 to 1.848\n",
      "Test - WHIP range: 1.028 to 1.776\n",
      "\n",
      "Created derived feature: K_per_9\n",
      "Train - K_per_9 range: 2.102 to 9.353\n",
      "Test - K_per_9 range: 2.064 to 8.704\n",
      "\n",
      "Created derived feature: HR_per_9\n",
      "Train - HR_per_9 range: 0.032 to 1.610\n",
      "Test - HR_per_9 range: 0.040 to 1.429\n",
      "\n",
      "Created derived feature: REI\n",
      "Train - REI range: 1.475 to 2.545\n",
      "Test - REI range: 1.554 to 2.402\n",
      "\n",
      "Created derived feature: PEI\n",
      "Train - PEI range: 0.975 to 28.452\n",
      "Test - PEI range: 1.215 to 27.720\n",
      "\n",
      "Created derived feature: Era_Adjusted_OBP\n",
      "Train - Era_Adjusted_OBP range: 0.246 to 0.434\n",
      "Test - Era_Adjusted_OBP range: 0.254 to 0.405\n",
      "\n",
      "Created derived feature: Era_Adjusted_SLG\n",
      "Train - Era_Adjusted_SLG range: 0.289 to 0.501\n",
      "Test - Era_Adjusted_SLG range: 0.298 to 0.482\n",
      "\n",
      "Created derived feature: Era_Adjusted_OPS\n",
      "Train - Era_Adjusted_OPS range: 0.536 to 0.910\n",
      "Test - Era_Adjusted_OPS range: 0.564 to 0.850\n",
      "\n",
      "Created derived feature: Era_Adjusted_WHIP\n",
      "Train - Era_Adjusted_WHIP range: 1.084 to 1.882\n",
      "Test - Era_Adjusted_WHIP range: 1.127 to 1.707\n",
      "\n",
      "Created derived feature: Era_Adjusted_K_per_9\n",
      "Train - Era_Adjusted_K_per_9 range: 1.847 to 9.626\n",
      "Test - Era_Adjusted_K_per_9 range: 1.795 to 8.963\n",
      "\n",
      "Created derived feature: Era_Adjusted_HR_per_9\n",
      "Train - Era_Adjusted_HR_per_9 range: 0.040 to 1.584\n",
      "Test - Era_Adjusted_HR_per_9 range: 0.043 to 1.347\n",
      "\n",
      "Created derived feature: Era_Adjusted_BB_Rate\n",
      "Train - Era_Adjusted_BB_Rate range: 0.049 to 0.136\n",
      "Test - Era_Adjusted_BB_Rate range: 0.046 to 0.133\n",
      "\n",
      "Created derived feature: Era_Adjusted_HR_Rate\n",
      "Train - Era_Adjusted_HR_Rate range: 0.001 to 0.047\n",
      "Test - Era_Adjusted_HR_Rate range: 0.001 to 0.043\n"
     ]
    }
   ],
   "source": [
    "# Create derived features for both train and test sets\n",
    "\n",
    "# R_per_game: Runs per game\n",
    "# RA_per_game: Runs allowed per game\n",
    "train_df['R_per_game'] = train_df['R'] / train_df['G']\n",
    "train_df['RA_per_game'] = train_df['RA'] / train_df['G']\n",
    "test_df['R_per_game'] = test_df['R'] / test_df['G']\n",
    "test_df['RA_per_game'] = test_df['RA'] / test_df['G']\n",
    "\n",
    "print(f\"\\nCreated derived features: R_per_game, RA_per_game\")\n",
    "print(f\"Train - R_per_game range: {train_df['R_per_game'].min():.3f} to {train_df['R_per_game'].max():.3f}\")\n",
    "print(f\"Train - RA_per_game range: {train_df['RA_per_game'].min():.3f} to {train_df['RA_per_game'].max():.3f}\")\n",
    "print(f\"Test - R_per_game range: {test_df['R_per_game'].min():.3f} to {test_df['R_per_game'].max():.3f}\")\n",
    "print(f\"Test - RA_per_game range: {test_df['RA_per_game'].min():.3f} to {test_df['RA_per_game'].max():.3f}\")\n",
    "\n",
    "# Expected Wins of Season = G × (R²) / (R² + RA²)\n",
    "train_df['Expected_Wins'] = train_df['G'] * (train_df['R_per_game'] ** 2) / ((train_df['R_per_game'] ** 2) + (train_df['RA_per_game'] ** 2))\n",
    "test_df['Expected_Wins'] = test_df['G'] * (test_df['R_per_game'] ** 2) / ((test_df['R_per_game'] ** 2) + (test_df['RA_per_game'] ** 2))\n",
    "# train_df['Expected_Wins'] = train_df['G'] * (train_df['R'] ** 2) / ((train_df['R'] ** 2) + (train_df['RA'] ** 2))\n",
    "# test_df['Expected_Wins'] = test_df['G'] * (test_df['R'] ** 2) / ((test_df['R'] ** 2) + (test_df['RA'] ** 2))\n",
    "print(f\"\\nCreated derived feature: Expected_Wins\")   \n",
    "print(f\"Train - Expected_Wins range: {train_df['Expected_Wins'].min():.3f} to {train_df['Expected_Wins'].max():.3f}\")\n",
    "print(f\"Test - Expected_Wins range: {test_df['Expected_Wins'].min():.3f} to {test_df['Expected_Wins'].max():.3f}\")\n",
    "\n",
    "# Times getting on base\n",
    "train_df['Times_On_Base'] = train_df['H'] + train_df['BB']\n",
    "test_df['Times_On_Base'] = test_df['H'] + test_df['BB']\n",
    "\n",
    "print(f\"\\nCreated derived feature: Times_On_Base\")\n",
    "print(f\"Train - Times_On_Base range: {train_df['Times_On_Base'].min():.3f} to {train_df['Times_On_Base'].max():.3f}\")\n",
    "print(f\"Test - Times_On_Base range: {test_df['Times_On_Base'].min():.3f} to {test_df['Times_On_Base'].max():.3f}\")\n",
    "\n",
    "# BB Rate (Walk Percentage) - BB / AB + BB\n",
    "train_df['BB_Rate'] = train_df['BB'] / (train_df['AB'] + train_df['BB'])\n",
    "test_df['BB_Rate'] = test_df['BB'] / (test_df['AB'] + test_df['BB'])\n",
    "\n",
    "print(f\"\\nCreated derived feature: BB_Rate\")\n",
    "print(f\"Train - BB_Rate range: {train_df['BB_Rate'].min():.3f} to {train_df['BB_Rate'].max():.3f}\") \n",
    "print(f\"Test - BB_Rate range: {test_df['BB_Rate'].min():.3f} to {test_df['BB_Rate'].max():.3f}\")\n",
    "\n",
    "# Home Run Rate - HR / AB\n",
    "train_df['HR_Rate'] = train_df['HR'] / train_df['AB']\n",
    "test_df['HR_Rate'] = test_df['HR'] / test_df['AB']\n",
    "\n",
    "print(f\"\\nCreated derived feature: HR_Rate\")\n",
    "print(f\"Train - HR_Rate range: {train_df['HR_Rate'].min():.3f} to {train_df['HR_Rate'].max():.3f}\")\n",
    "print(f\"Test - HR_Rate range: {test_df['HR_Rate'].min():.3f} to {test_df['HR_Rate'].max():.3f}\")\n",
    "\n",
    "# On-Base Percentage (OBP) - (H + BB) / (AB + BB)\n",
    "train_df['OBP'] = (train_df['H'] + train_df['BB']) / (train_df['AB'] + train_df['BB'])\n",
    "test_df['OBP'] = (test_df['H'] + test_df['BB']) / (test_df['AB'] + test_df['BB'])\n",
    "\n",
    "print(f\"\\nCreated derived feature: OBP\")\n",
    "print(f\"Train - OBP range: {train_df['OBP'].min():.3f} to {train_df['OBP'].max():.3f}\") \n",
    "print(f\"Test - OBP range: {test_df['OBP'].min():.3f} to {test_df['OBP'].max():.3f}\")\n",
    "\n",
    "# Slugging Percentage (SLG)\n",
    "# Singles = H - (2B + 3B + HR)\n",
    "# Total Bases = Singles + (2 * 2B) + (3 * 3B) + (4 * HR)\n",
    "# SLG = Total Bases / AB\n",
    "Singles_train = train_df['H'] - (train_df['2B'] + train_df['3B'] + train_df['HR'])\n",
    "Total_Bases_train = Singles_train + (2 * train_df['2B']) + (3 * train_df['3B']) + (4 * train_df['HR'])\n",
    "train_df['SLG'] = Total_Bases_train / train_df['AB']  \n",
    "\n",
    "Singles_test = test_df['H'] - (test_df['2B'] + test_df['3B'] + test_df['HR'])\n",
    "Total_Bases_test = Singles_test + (2 * test_df['2B']) + (3 * test_df['3B']) + (4 * test_df['HR'])\n",
    "test_df['SLG'] = Total_Bases_test / test_df['AB']\n",
    "\n",
    "print(f\"\\nCreated derived feature: SLG\")\n",
    "print(f\"Train - SLG range: {train_df['SLG'].min():.3f} to {train_df['SLG'].max():.3f}\") \n",
    "print(f\"Test - SLG range: {test_df['SLG'].min():.3f} to {test_df['SLG'].max():.3f}\")    \n",
    "\n",
    "# Combined On-Base Plus Slugging (OPS) - OBP + SLG\n",
    "train_df['OPS'] = train_df['OBP'] + train_df['SLG']\n",
    "test_df['OPS'] = test_df['OBP'] + test_df['SLG']\n",
    "\n",
    "print(f\"\\nCreated derived feature: OPS\")\n",
    "print(f\"Train - OPS range: {train_df['OPS'].min():.3f} to {train_df['OPS'].max():.3f}\") \n",
    "print(f\"Test - OPS range: {test_df['OPS'].min():.3f} to {test_df['OPS'].max():.3f}\")\n",
    "\n",
    "# Time on Base Allowed - HA + BBA\n",
    "train_df['Times_On_Base_Allowed'] = train_df['HA'] + train_df['BBA']\n",
    "test_df['Times_On_Base_Allowed'] = test_df['HA'] + test_df['BBA']\n",
    "\n",
    "print(f\"\\nCreated derived feature: Times_On_Base_Allowed\")\n",
    "print(f\"Train - Times_On_Base_Allowed range: {train_df['Times_On_Base_Allowed'].min():.3f} to {train_df['Times_On_Base_Allowed'].max():.3f}\")\n",
    "print(f\"Test - Times_On_Base_Allowed range: {test_df['Times_On_Base_Allowed'].min():.3f} to {test_df['Times_On_Base_Allowed'].max():.3f}\")\n",
    "\n",
    "# WHIP (Walks plus Hits per Inning Pitched)\n",
    "# Inings Pitched = IPouts / 3\n",
    "# Times_On_Base_Per_Inning = Times_On_Base_Allowed / Inings_Pitched\n",
    "train_df['Innings_Pitched'] = train_df['IPouts'] / 3\n",
    "train_df['WHIP'] = train_df['Times_On_Base_Allowed'] / train_df['Innings_Pitched']\n",
    "test_df['Innings_Pitched'] = test_df['IPouts'] / 3\n",
    "test_df['WHIP'] = test_df['Times_On_Base_Allowed'] / test_df['Innings_Pitched']\n",
    "\n",
    "print(f\"\\nCreated derived feature: WHIP\")\n",
    "print(f\"Train - WHIP range: {train_df['WHIP'].min():.3f} to {train_df['WHIP'].max():.3f}\")\n",
    "print(f\"Test - WHIP range: {test_df['WHIP'].min():.3f} to {test_df['WHIP'].max():.3f}\")\n",
    "\n",
    "# K/9 (Strikeouts per 9 Innings) - SOA / Innings_Pitched * 9\n",
    "train_df['K_per_9'] = (train_df['SOA'] / train_df['Innings_Pitched']) * 9\n",
    "test_df['K_per_9'] = (test_df['SOA'] / test_df['Innings_Pitched']) * 9  \n",
    "\n",
    "print(f\"\\nCreated derived feature: K_per_9\")\n",
    "print(f\"Train - K_per_9 range: {train_df['K_per_9'].min():.3f} to {train_df['K_per_9'].max():.3f}\")\n",
    "print(f\"Test - K_per_9 range: {test_df['K_per_9'].min():.3f} to {test_df['K_per_9'].max():.3f}\")\n",
    "\n",
    "# HR/9 (Home Runs Allowed per 9 Innings) - HRA / Innings_Pitched * 9\n",
    "train_df['HR_per_9'] = (train_df['HRA'] / train_df['Innings_Pitched']) * 9\n",
    "test_df['HR_per_9'] = (test_df['HRA'] / test_df['Innings_Pitched']) * 9\n",
    "\n",
    "print(f\"\\nCreated derived feature: HR_per_9\")\n",
    "print(f\"Train - HR_per_9 range: {train_df['HR_per_9'].min():.3f} to {train_df['HR_per_9'].max():.3f}\")\n",
    "print(f\"Test - HR_per_9 range: {test_df['HR_per_9'].min():.3f} to {test_df['HR_per_9'].max():.3f}\")\n",
    "\n",
    "# Run Environment Idex (REI) - (R + RA) / G / mlb_rpg\n",
    "train_df['REI'] = (train_df['R'] + train_df['RA']) / train_df['G'] / train_df['mlb_rpg']\n",
    "test_df['REI'] = (test_df['R'] + test_df['RA']) / test_df['G'] / test_df['mlb_rpg']\n",
    "print(f\"\\nCreated derived feature: REI\")\n",
    "print(f\"Train - REI range: {train_df['REI'].min():.3f} to {train_df['REI'].max():.3f}\")\n",
    "print(f\"Test - REI range: {test_df['REI'].min():.3f} to {test_df['REI'].max():.3f}\")    \n",
    "\n",
    "# Power Environement Index (PEI) -  (HR + HRA) / G / (mlb_rpg * avg_hr_rate)\n",
    "avg_hr_rate = train_df['HR_Rate'].mean()\n",
    "train_df['PEI'] = (train_df['HR'] + train_df['HRA']) / train_df['G'] / (train_df['mlb_rpg'] * avg_hr_rate)\n",
    "test_df['PEI'] = (test_df['HR'] + test_df['HRA']) / test_df['G'] / (test_df['mlb_rpg'] * avg_hr_rate)\n",
    "print(f\"\\nCreated derived feature: PEI\")\n",
    "print(f\"Train - PEI range: {train_df['PEI'].min():.3f} to {train_df['PEI'].max():.3f}\")\n",
    "print(f\"Test - PEI range: {test_df['PEI'].min():.3f} to {test_df['PEI'].max():.3f}\") \n",
    "\n",
    "# Era adjusted OBP, SLG, OPS, WHIP, K_per_9, HR_per_9, BB_Rate, HR_Rate\n",
    "# Historical average runs per game (RPG) for MLB\n",
    "historical_avg_rpg_train = train_df['mlb_rpg'].mean()\n",
    "historical_avg_rpg_test = test_df['mlb_rpg'].mean()\n",
    "# historical_avg_rpg_train = 4.4\n",
    "# historical_avg_rpg_test = 4.4\n",
    "\n",
    "# Era adjusted OBP\n",
    "train_df['Era_Adjusted_OBP'] = train_df['OBP'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_OBP'] = test_df['OBP'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_OBP\")\n",
    "print(f\"Train - Era_Adjusted_OBP range: {train_df['Era_Adjusted_OBP'].min():.3f} to {train_df['Era_Adjusted_OBP'].max():.3f}\") \n",
    "print(f\"Test - Era_Adjusted_OBP range: {test_df['Era_Adjusted_OBP'].min():.3f} to {test_df['Era_Adjusted_OBP'].max():.3f}\") \n",
    "\n",
    "# Era adjusted SLG\n",
    "train_df['Era_Adjusted_SLG'] = train_df['SLG'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_SLG'] = test_df['SLG'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_SLG\")\n",
    "print(f\"Train - Era_Adjusted_SLG range: {train_df['Era_Adjusted_SLG'].min():.3f} to {train_df['Era_Adjusted_SLG'].max():.3f}\") \n",
    "print(f\"Test - Era_Adjusted_SLG range: {test_df['Era_Adjusted_SLG'].min():.3f} to {test_df['Era_Adjusted_SLG'].max():.3f}\") \n",
    "\n",
    "# Era adjusted OPS\n",
    "train_df['Era_Adjusted_OPS'] = train_df['OPS'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_OPS'] = test_df['OPS'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_OPS\")\n",
    "print(f\"Train - Era_Adjusted_OPS range: {train_df['Era_Adjusted_OPS'].min():.3f} to {train_df['Era_Adjusted_OPS'].max():.3f}\") \n",
    "print(f\"Test - Era_Adjusted_OPS range: {test_df['Era_Adjusted_OPS'].min():.3f} to {test_df['Era_Adjusted_OPS'].max():.3f}\")\n",
    "\n",
    "# Era adjusted WHIP\n",
    "train_df['Era_Adjusted_WHIP'] = train_df['WHIP'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_WHIP'] = test_df['WHIP'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_WHIP\")\n",
    "print(f\"Train - Era_Adjusted_WHIP range: {train_df['Era_Adjusted_WHIP'].min():.3f} to {train_df['Era_Adjusted_WHIP'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_WHIP range: {test_df['Era_Adjusted_WHIP'].min():.3f} to {test_df['Era_Adjusted_WHIP'].max():.3f}\")\n",
    "\n",
    "# Era adjusted K_per_9\n",
    "train_df['Era_Adjusted_K_per_9'] = train_df['K_per_9'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_K_per_9'] = test_df['K_per_9'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_K_per_9\")\n",
    "print(f\"Train - Era_Adjusted_K_per_9 range: {train_df['Era_Adjusted_K_per_9'].min():.3f} to {train_df['Era_Adjusted_K_per_9'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_K_per_9 range: {test_df['Era_Adjusted_K_per_9'].min():.3f} to {test_df['Era_Adjusted_K_per_9'].max():.3f}\") \n",
    "\n",
    "# Era adjusted HR_per_9\n",
    "train_df['Era_Adjusted_HR_per_9'] = train_df['HR_per_9'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_HR_per_9'] = test_df['HR_per_9'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_HR_per_9\")\n",
    "print(f\"Train - Era_Adjusted_HR_per_9 range: {train_df['Era_Adjusted_HR_per_9'].min():.3f} to {train_df['Era_Adjusted_HR_per_9'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_HR_per_9 range: {test_df['Era_Adjusted_HR_per_9'].min():.3f} to {test_df['Era_Adjusted_HR_per_9'].max():.3f}\")\n",
    "\n",
    "# Era adjusted BB_Rate\n",
    "train_df['Era_Adjusted_BB_Rate'] = train_df['BB_Rate'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_BB_Rate'] = test_df['BB_Rate'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_BB_Rate\")\n",
    "print(f\"Train - Era_Adjusted_BB_Rate range: {train_df['Era_Adjusted_BB_Rate'].min():.3f} to {train_df['Era_Adjusted_BB_Rate'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_BB_Rate range: {test_df['Era_Adjusted_BB_Rate'].min():.3f} to {test_df['Era_Adjusted_BB_Rate'].max():.3f}\") \n",
    "\n",
    "# Era adjusted HR_Rate\n",
    "train_df['Era_Adjusted_HR_Rate'] = train_df['HR_Rate'] * (historical_avg_rpg_train / train_df['mlb_rpg'])\n",
    "test_df['Era_Adjusted_HR_Rate'] = test_df['HR_Rate'] * (historical_avg_rpg_test / test_df['mlb_rpg'])\n",
    "print(f\"\\nCreated derived feature: Era_Adjusted_HR_Rate\")\n",
    "print(f\"Train - Era_Adjusted_HR_Rate range: {train_df['Era_Adjusted_HR_Rate'].min():.3f} to {train_df['Era_Adjusted_HR_Rate'].max():.3f}\")\n",
    "print(f\"Test - Era_Adjusted_HR_Rate range: {test_df['Era_Adjusted_HR_Rate'].min():.3f} to {test_df['Era_Adjusted_HR_Rate'].max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d71b7c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available default features: 65\n",
      "Available features:\n",
      "G\n",
      "R\n",
      "AB\n",
      "H\n",
      "2B\n",
      "3B\n",
      "HR\n",
      "BB\n",
      "SO\n",
      "SB\n",
      "RA\n",
      "ER\n",
      "ERA\n",
      "CG\n",
      "SHO\n",
      "SV\n",
      "IPouts\n",
      "HA\n",
      "HRA\n",
      "BBA\n",
      "SOA\n",
      "E\n",
      "DP\n",
      "FP\n",
      "Expected_Wins\n",
      "Times_On_Base\n",
      "Times_On_Base_Allowed\n",
      "mlb_rpg\n",
      "Era_Adjusted_OBP\n",
      "Era_Adjusted_SLG\n",
      "Era_Adjusted_OPS\n",
      "Era_Adjusted_WHIP\n",
      "Era_Adjusted_K_per_9\n",
      "Era_Adjusted_HR_per_9\n",
      "Era_Adjusted_BB_Rate\n",
      "Era_Adjusted_HR_Rate\n",
      "OBP\n",
      "SLG\n",
      "OPS\n",
      "WHIP\n",
      "K_per_9\n",
      "HR_per_9\n",
      "BB_Rate\n",
      "HR_Rate\n",
      "PEI\n",
      "REI\n",
      "era_1\n",
      "era_2\n",
      "era_3\n",
      "era_4\n",
      "era_5\n",
      "era_6\n",
      "era_7\n",
      "era_8\n",
      "decade_1910\n",
      "decade_1920\n",
      "decade_1930\n",
      "decade_1940\n",
      "decade_1950\n",
      "decade_1960\n",
      "decade_1970\n",
      "decade_1980\n",
      "decade_1990\n",
      "decade_2000\n",
      "decade_2010\n"
     ]
    }
   ],
   "source": [
    "default_features = [\n",
    "    # Basic Statistics\n",
    "    'G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'CS', 'HBP', 'SF',\n",
    "    'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA',\n",
    "    'E', 'DP', 'FP', 'attendance', 'BPF', 'PPF',\n",
    "    \n",
    "    # Derived Features\n",
    "    'Expected_Wins', 'Times_On_Base', 'Times_On_Base_Allowed', 'mlb_rpg',\n",
    "\n",
    "    'Era_Adjusted_OBP', 'Era_Adjusted_SLG', 'Era_Adjusted_OPS', 'Era_Adjusted_WHIP',\n",
    "    'Era_Adjusted_K_per_9', 'Era_Adjusted_HR_per_9', 'Era_Adjusted_BB_Rate', 'Era_Adjusted_HR_Rate',\n",
    "    \n",
    "    'OBP', 'SLG', 'OPS', 'WHIP', 'K_per_9', 'HR_per_9', 'BB_Rate', 'HR_Rate', \n",
    "    \n",
    "    'PEI', 'REI',\n",
    "    \n",
    "    # Era Indicators\n",
    "    'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8',\n",
    "    \n",
    "    # Decade Indicators\n",
    "    'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950',\n",
    "    'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010'\n",
    " ]\n",
    "\n",
    "# Filter features that exist in both training data AND test data\n",
    "available_features = [col for col in default_features \n",
    "                     if col in train_df.columns and col in test_df.columns]\n",
    "print(f\"Number of available default features: {len(available_features)}\")\n",
    "\n",
    "# Print available features in a column\n",
    "print(\"Available features:\")\n",
    "for feature in available_features:\n",
    "    print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5edd8c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1449, 65)\n",
      "Validation set shape: (363, 65)\n",
      "Final test set shape: (453, 65)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data (split the train.csv for model evaluation)\n",
    "X_full = train_df[available_features]\n",
    "y_full = train_df['W']\n",
    "\n",
    "# Split training data into train/validation sets for model evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare final test data for predictions (this has no target variable)\n",
    "X_test_final = test_df[available_features]\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Final test set shape: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bae5ffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CORRELATION ANALYSIS\n",
      "==================================================\n",
      "Correlation threshold: 0.95\n",
      "Original features: 65\n",
      "Features to remove: 13\n",
      "\n",
      "Highly correlated features to remove:\n",
      "  • ERA (corr=0.959 with RA)\n",
      "  • FP (corr=0.996 with E)\n",
      "  • Era_Adjusted_K_per_9 (corr=0.953 with SOA)\n",
      "  • Era_Adjusted_HR_per_9 (corr=0.981 with HRA)\n",
      "  • Era_Adjusted_HR_Rate (corr=0.979 with HR)\n",
      "  • OPS (corr=0.969 with SLG)\n",
      "  • K_per_9 (corr=0.999 with SOA)\n",
      "  • HR_per_9 (corr=0.999 with HRA)\n",
      "  • BB_Rate (corr=0.982 with BB)\n",
      "  • HR_Rate (corr=0.999 with HR)\n",
      "  • PEI (corr=0.959 with Era_Adjusted_HR_Rate)\n",
      "  • decade_1910 (corr=1.000 with era_1)\n",
      "  • decade_2010 (corr=1.000 with era_8)\n",
      "\n",
      "Features after removal: 52\n",
      "Features removed: 13\n",
      "Dimensionality reduction: 20.0%\n",
      "\n",
      "📊 UPDATED DATASET INFO\n",
      "==================================================\n",
      "X_full shape: (1812, 52)\n",
      "X_test_final shape: (453, 52)\n",
      "Available features updated: 52\n",
      "✅ Feature alignment verified between train and test sets\n",
      "\n",
      "🔄 Variables updated for downstream compatibility:\n",
      "  • X_full: (1812, 52)\n",
      "  • X_test_final: (453, 52)\n",
      "  • available_features: 52 features\n",
      "\n",
      "💡 To disable correlation removal, simply comment out this entire cell\n"
     ]
    }
   ],
   "source": [
    "# Remove highly correlated features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def remove_correlated_features(X_train, X_test, threshold=0.95, verbose=True):\n",
    "    \"\"\"\n",
    "    Remove highly correlated features from training and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training feature DataFrame\n",
    "    - X_test: Test feature DataFrame  \n",
    "    - threshold: Correlation threshold (default 0.95)\n",
    "    - verbose: Print information about removed features\n",
    "    \n",
    "    Returns:\n",
    "    - X_train_filtered, X_test_filtered: DataFrames with correlated features removed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    \n",
    "    # Find pairs of highly correlated features\n",
    "    upper_tri = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # Find features to remove (those with correlation > threshold)\n",
    "    features_to_remove = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"🔍 CORRELATION ANALYSIS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Correlation threshold: {threshold}\")\n",
    "        print(f\"Original features: {X_train.shape[1]}\")\n",
    "        print(f\"Features to remove: {len(features_to_remove)}\")\n",
    "        \n",
    "        if features_to_remove:\n",
    "            print(f\"\\nHighly correlated features to remove:\")\n",
    "            for feature in features_to_remove:\n",
    "                # Find what it's correlated with\n",
    "                high_corr = upper_tri[feature].dropna()\n",
    "                high_corr = high_corr[high_corr > threshold]\n",
    "                if len(high_corr) > 0:\n",
    "                    corr_with = high_corr.index[0]\n",
    "                    corr_value = high_corr.iloc[0]\n",
    "                    print(f\"  • {feature} (corr={corr_value:.3f} with {corr_with})\")\n",
    "        else:\n",
    "            print(f\"\\n✅ No highly correlated features found above threshold {threshold}\")\n",
    "    \n",
    "    # Remove highly correlated features from both datasets\n",
    "    X_train_filtered = X_train.drop(columns=features_to_remove)\n",
    "    X_test_filtered = X_test.drop(columns=features_to_remove)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nFeatures after removal: {X_train_filtered.shape[1]}\")\n",
    "        print(f\"Features removed: {len(features_to_remove)}\")\n",
    "        if len(features_to_remove) > 0:\n",
    "            improvement = len(features_to_remove) / X_train.shape[1] * 100\n",
    "            print(f\"Dimensionality reduction: {improvement:.1f}%\")\n",
    "    \n",
    "    return X_train_filtered, X_test_filtered\n",
    "\n",
    "# Apply correlation removal to our datasets\n",
    "# Store original datasets for backup\n",
    "X_full_original = X_full.copy()\n",
    "X_test_final_original = X_test_final.copy()\n",
    "\n",
    "# Remove correlated features\n",
    "X_full_filtered, X_test_final_filtered = remove_correlated_features(\n",
    "    X_full, X_test_final, \n",
    "    threshold=0.95, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Update the main datasets (so later cells use the filtered versions)\n",
    "X_full = X_full_filtered\n",
    "X_test_final = X_test_final_filtered\n",
    "\n",
    "# Update available_features list to match the filtered features\n",
    "available_features_filtered = list(X_full.columns)\n",
    "\n",
    "print(f\"\\n📊 UPDATED DATASET INFO\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"X_full shape: {X_full.shape}\")\n",
    "print(f\"X_test_final shape: {X_test_final.shape}\")\n",
    "print(f\"Available features updated: {len(available_features_filtered)}\")\n",
    "\n",
    "# Verify both datasets have the same features\n",
    "assert list(X_full.columns) == list(X_test_final.columns), \"Feature mismatch between train and test!\"\n",
    "print(f\"✅ Feature alignment verified between train and test sets\")\n",
    "\n",
    "# Update available_features for downstream compatibility\n",
    "available_features = available_features_filtered\n",
    "\n",
    "print(f\"\\n🔄 Variables updated for downstream compatibility:\")\n",
    "print(f\"  • X_full: {X_full.shape}\")\n",
    "print(f\"  • X_test_final: {X_test_final.shape}\")  \n",
    "print(f\"  • available_features: {len(available_features)} features\")\n",
    "print(f\"\\n💡 To disable correlation removal, simply comment out this entire cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c37fccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOSTING MODELS COMPARISON\n",
      "==================================================\n",
      "\n",
      "Dataset shape: (1812, 52)\n",
      "Features being used: ['G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'RA', 'ER', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA', 'E', 'DP', 'Expected_Wins', 'Times_On_Base', 'Times_On_Base_Allowed', 'mlb_rpg', 'Era_Adjusted_OBP', 'Era_Adjusted_SLG', 'Era_Adjusted_OPS', 'Era_Adjusted_WHIP', 'Era_Adjusted_BB_Rate', 'OBP', 'SLG', 'WHIP', 'REI', 'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950', 'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000']\n",
      "\n",
      "Testing XGBoost...\n",
      "\n",
      "Testing LightGBM...\n",
      "\n",
      "Testing CatBoost...\n",
      "\n",
      "==========================================================================================\n",
      "RESULTS SUMMARY\n",
      "==========================================================================================\n",
      "Model                  Test R²    Test MAE    Overfitting   Time (s)  \n",
      "------------------------------------------------------------------------------------------\n",
      "CatBoost               0.9120    3.07       0.0153 ✓        2.4\n",
      "XGBoost                0.9081    3.16       0.0346 ✓        0.5\n",
      "LightGBM               0.9039    3.22       0.0456 ✓        5.6\n",
      "\n",
      "🏆 Best Model: CatBoost\n",
      "Training CatBoost on full dataset for feature importance...\n",
      "\n",
      "Top 15 Features from CatBoost:\n",
      "----------------------------------------\n",
      "       Expected_Wins: 92.3051\n",
      "                  SV: 4.7592\n",
      "                  CG: 0.7943\n",
      "                 OBP: 0.7619\n",
      "                 SHO: 0.5500\n",
      "              IPouts: 0.1305\n",
      "                   R: 0.1302\n",
      "                  2B: 0.0842\n",
      "                WHIP: 0.0770\n",
      "               era_2: 0.0719\n",
      "                  RA: 0.0459\n",
      "                 SLG: 0.0431\n",
      "         decade_1970: 0.0324\n",
      "    Era_Adjusted_SLG: 0.0233\n",
      "                 REI: 0.0212\n"
     ]
    }
   ],
   "source": [
    "# Import boosting libraries\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Silence XGBoost FutureWarnings about deprecated pandas functions\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
    "\n",
    "print(\"BOOSTING MODELS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Prepare data\n",
    "X = X_full\n",
    "y = y_full\n",
    "\n",
    "print(f\"\\nDataset shape: {X.shape}\")\n",
    "print(f\"Features being used: {list(X.columns)}\")\n",
    "\n",
    "# Define models with GPU acceleration where available\n",
    "models = {\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=100,  # 🔧 Reduced from 200\n",
    "        max_depth=4,       # 🔧 Reduced from 6\n",
    "        learning_rate=0.05, # 🔧 Reduced from 0.1\n",
    "        subsample=0.7,     # 🔧 Reduced from 0.8\n",
    "        colsample_bytree=0.7, # 🔧 Reduced from 0.8\n",
    "        reg_alpha=1.0,     # 🔧 Added L1 regularization\n",
    "        reg_lambda=1.0,    # 🔧 Added L2 regularization\n",
    "        min_child_weight=3, # 🔧 Added minimum samples per leaf\n",
    "        random_state=42,\n",
    "        verbosity=0,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\"  # 🚀 GPU acceleration\n",
    "    ),\n",
    "    \n",
    "    'LightGBM': LGBMRegressor(\n",
    "        n_estimators=80,     # 🔧 Reduced from 100 to 80\n",
    "        max_depth=3,         # 🔧 Reduced from 4 to 3 (shallower trees)\n",
    "        learning_rate=0.04,  # 🔧 Reduced from 0.05 to 0.04\n",
    "        subsample=0.6,       # 🔧 Reduced from 0.7 to 0.6 (more aggressive sampling)\n",
    "        colsample_bytree=0.6, # 🔧 Reduced from 0.7 to 0.6 (fewer features per tree)\n",
    "        reg_alpha=2.0,       # 🔧 Increased from 1.0 to 2.0 (stronger L1)\n",
    "        reg_lambda=2.0,      # 🔧 Increased from 1.0 to 2.0 (stronger L2)\n",
    "        min_child_samples=15, # 🔧 Increased from 10 to 15 (larger min samples)\n",
    "        min_child_weight=0.01, # 🔧 Added minimum child weight\n",
    "        bagging_freq=1,      # 🔧 Added bagging frequency\n",
    "        feature_fraction=0.6, # 🔧 Added feature fraction (same as colsample_bytree)\n",
    "        random_state=42,\n",
    "        verbose=-1,\n",
    "        device='cuda'  # 🚀 GPU acceleration\n",
    "    ),\n",
    "    \n",
    "    'CatBoost': CatBoostRegressor(\n",
    "        iterations=100,    # 🔧 Reduced from 200\n",
    "        depth=4,          # 🔧 Reduced from 6\n",
    "        learning_rate=0.05, # 🔧 Reduced from 0.1\n",
    "        l2_leaf_reg=3,    # 🔧 Added L2 regularization\n",
    "        bagging_temperature=0.2, # 🔧 Added bagging regularization\n",
    "        random_strength=0.2,     # 🔧 Added random strength\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        task_type=\"GPU\"  # 🚀 GPU acceleration\n",
    "    )\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTesting {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get both R² and MAE\n",
    "        cv_scores = cross_validate(\n",
    "            model, X, y, \n",
    "            cv=5, \n",
    "            scoring=['r2', 'neg_mean_absolute_error'],\n",
    "            return_train_score=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        cv_results[name] = {\n",
    "            'test_r2': cv_scores['test_r2'].mean(),\n",
    "            'test_r2_std': cv_scores['test_r2'].std(),\n",
    "            'test_mae': -cv_scores['test_neg_mean_absolute_error'].mean(),\n",
    "            'test_mae_std': cv_scores['test_neg_mean_absolute_error'].std(),\n",
    "            'train_r2': cv_scores['train_r2'].mean(),\n",
    "            'overfitting': cv_scores['train_r2'].mean() - cv_scores['test_r2'].mean(),\n",
    "            'time': end_time - start_time,\n",
    "            'gpu_status': '✅ GPU'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ GPU failed, falling back to CPU: {str(e)}\")\n",
    "        # Fallback to CPU version\n",
    "        if name == 'XGBoost':\n",
    "            model.set_params(device=\"cpu\")\n",
    "        elif name == 'LightGBM':\n",
    "            model.set_params(device=\"cpu\")\n",
    "        elif name == 'CatBoost':\n",
    "            model.set_params(task_type=\"CPU\")\n",
    "            \n",
    "        cv_scores = cross_validate(\n",
    "            model, X, y, \n",
    "            cv=5, \n",
    "            scoring=['r2', 'neg_mean_absolute_error'],\n",
    "            return_train_score=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        cv_results[name] = {\n",
    "            'test_r2': cv_scores['test_r2'].mean(),\n",
    "            'test_r2_std': cv_scores['test_r2'].std(),\n",
    "            'test_mae': -cv_scores['test_neg_mean_absolute_error'].mean(),\n",
    "            'test_mae_std': cv_scores['test_neg_mean_absolute_error'].std(),\n",
    "            'train_r2': cv_scores['train_r2'].mean(),\n",
    "            'overfitting': cv_scores['train_r2'].mean() - cv_scores['test_r2'].mean(),\n",
    "            'time': end_time - start_time,\n",
    "            'gpu_status': '⚠️ CPU fallback'\n",
    "        }\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Model':<22} {'Test R²':<10} {'Test MAE':<11} {'Overfitting':<13} {'Time (s)':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for name, result in sorted(cv_results.items(), key=lambda x: x[1]['test_r2'], reverse=True):\n",
    "    overfit_warning = \"⚠️\" if result['overfitting'] > 0.05 else \"✓\"\n",
    "    print(f\"{name:<22} {result['test_r2']:.4f}    {result['test_mae']:.2f}       \"\n",
    "          f\"{result['overfitting']:>6.4f} {overfit_warning:<5} {result['time']:>6.1f}\")\n",
    "\n",
    "# Feature importance for best model\n",
    "best_model_name = max(cv_results.keys(), key=lambda x: cv_results[x]['test_r2'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\n🏆 Best Model: {best_model_name}\")\n",
    "print(f\"Training {best_model_name} on full dataset for feature importance...\")\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 15 Features from {best_model_name}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, row in importance_df.head(15).iterrows():\n",
    "        print(f\"{row['feature']:>20}: {row['importance']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ebc9b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR MODELS COMPARISON\n",
      "======================================================================\n",
      "Dataset shape: (1812, 52)\n",
      "Using 52 engineered features\n",
      "\n",
      "Testing Linear Regression...\n",
      "Testing Ridge (alpha=0.1)...\n",
      "Testing Ridge (alpha=1.0)...\n",
      "Testing Ridge (alpha=10)...\n",
      "Testing Lasso (alpha=0.01)...\n",
      "Testing Lasso (alpha=0.1)...\n",
      "Testing Elastic Net...\n",
      "Testing Huber Regressor...\n",
      "Testing Polynomial Ridge...\n",
      "\n",
      "==========================================================================================\n",
      "RESULTS SUMMARY\n",
      "==========================================================================================\n",
      "Model                  Test R²    Test MAE    Overfitting   Time (s)  \n",
      "------------------------------------------------------------------------------------------\n",
      "Lasso (alpha=0.01)     0.9312    2.72       0.0041 ✓        0.2\n",
      "Ridge (alpha=10)       0.9308    2.73       0.0044 ✓        0.0\n",
      "Ridge (alpha=1.0)      0.9308    2.73       0.0051 ✓        0.0\n",
      "Ridge (alpha=0.1)      0.9305    2.73       0.0054 ✓        0.0\n",
      "Linear Regression      0.9301    2.74       0.0059 ✓        0.1\n",
      "Huber Regressor        0.9300    2.75       0.0057 ✓        0.5\n",
      "Polynomial Ridge       0.9246    2.85       0.0260 ✓        0.6\n",
      "Elastic Net            0.9235    2.88       0.0031 ✓        0.0\n",
      "Lasso (alpha=0.1)      0.9227    2.88       0.0030 ✓        0.1\n",
      "\n",
      "🏆 Best Linear Model: Lasso (alpha=0.01)\n",
      "   CV R² = 0.9312 (±0.0068)\n",
      "   CV MAE = 2.72 wins (±0.05)\n",
      "\n",
      "📊 FEATURE IMPORTANCE ANALYSIS\n",
      "--------------------------------------------------\n",
      "Training Lasso (alpha=0.01) on full dataset for feature importance...\n",
      "\n",
      "Top 15 Most Important Features (Lasso (alpha=0.01)):\n",
      "------------------------------------------------------------\n",
      "Feature                   Coefficient     Abs Value   \n",
      "------------------------------------------------------------\n",
      "Expected_Wins             +6.6528         6.6528      \n",
      "IPouts                    +4.3166         4.3166      \n",
      "AB                        -4.2808        4.2808      \n",
      "SV                        +4.2093         4.2093      \n",
      "CG                        +3.5848         3.5848      \n",
      "R                         +2.6255         2.6255      \n",
      "OBP                       +1.3100         1.3100      \n",
      "RA                        -1.0855        1.0855      \n",
      "H                         +1.0571         1.0571      \n",
      "WHIP                      -0.9922        0.9922      \n",
      "SLG                       +0.8647         0.8647      \n",
      "era_1                     -0.8343        0.8343      \n",
      "Era_Adjusted_BB_Rate      -0.7220        0.7220      \n",
      "G                         -0.6856        0.6856      \n",
      "E                         -0.6338        0.6338      \n",
      "\n",
      "Feature Importance Insights:\n",
      "• Positive coefficients increase wins\n",
      "• Negative coefficients decrease wins\n",
      "• Larger absolute values = stronger influence\n",
      "• Top 15 features: 8 positive, 7 negative coefficients\n"
     ]
    }
   ],
   "source": [
    "print(\"LINEAR MODELS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, HuberRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "import time\n",
    "\n",
    "# Prepare data\n",
    "X_linear = X_full\n",
    "y = y_full\n",
    "\n",
    "print(f\"Dataset shape: {X_linear.shape}\")\n",
    "print(f\"Using {len(available_features)} engineered features\\n\")\n",
    "\n",
    "# Define linear models with pipelines (include scaling)\n",
    "models_linear = {\n",
    "    'Linear Regression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearRegression())\n",
    "    ]),\n",
    "    \n",
    "    'Ridge (alpha=0.1)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=0.1))\n",
    "    ]),\n",
    "    \n",
    "    'Ridge (alpha=1.0)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=1.0))\n",
    "    ]),\n",
    "    \n",
    "    'Ridge (alpha=10)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=10.0))\n",
    "    ]),\n",
    "    \n",
    "    'Lasso (alpha=0.01)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(alpha=0.01, max_iter=5000))\n",
    "    ]),\n",
    "    \n",
    "    'Lasso (alpha=0.1)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(alpha=0.1, max_iter=5000))\n",
    "    ]),\n",
    "    \n",
    "    'Elastic Net': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=5000))\n",
    "    ]),\n",
    "    \n",
    "    'Huber Regressor': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', HuberRegressor(\n",
    "            epsilon=1.35, \n",
    "            max_iter=2000,  # 🔧 Increased from 1000 to 2000\n",
    "            alpha=0.0001,   # 🔧 Added regularization\n",
    "            tol=1e-05       # 🔧 Adjusted tolerance\n",
    "        ))\n",
    "    ]),\n",
    "    \n",
    "    'Polynomial Ridge': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=10.0))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_linear = {}\n",
    "\n",
    "# Test all models\n",
    "for name, model in models_linear.items():\n",
    "    print(f\"Testing {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        cv_scores = cross_validate(\n",
    "            model, X_linear, y,\n",
    "            cv=cv,\n",
    "            scoring=['r2', 'neg_mean_absolute_error'],\n",
    "            return_train_score=True,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        results_linear[name] = {\n",
    "            'test_r2': cv_scores['test_r2'].mean(),\n",
    "            'test_r2_std': cv_scores['test_r2'].std(),\n",
    "            'test_mae': -cv_scores['test_neg_mean_absolute_error'].mean(),\n",
    "            'test_mae_std': cv_scores['test_neg_mean_absolute_error'].std(),\n",
    "            'train_r2': cv_scores['train_r2'].mean(),\n",
    "            'overfitting': cv_scores['train_r2'].mean() - cv_scores['test_r2'].mean(),\n",
    "            'time': end_time - start_time,\n",
    "            'status': 'Success'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️  Error: {str(e)}\")\n",
    "        results_linear[name] = {'status': 'Failed', 'error': str(e)}\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Model':<22} {'Test R²':<10} {'Test MAE':<11} {'Overfitting':<13} {'Time (s)':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Sort by Test R²\n",
    "successful_results = {k: v for k, v in results_linear.items() if v.get('status') == 'Success'}\n",
    "sorted_results = sorted(successful_results.items(), key=lambda x: x[1]['test_r2'], reverse=True)\n",
    "\n",
    "for name, result in sorted_results:\n",
    "    overfit_warning = \"⚠️\" if result['overfitting'] > 0.05 else \"✓\"\n",
    "    print(f\"{name:<22} {result['test_r2']:.4f}    {result['test_mae']:.2f}       \"\n",
    "          f\"{result['overfitting']:>6.4f} {overfit_warning:<5} {result['time']:>6.1f}\")\n",
    "\n",
    "# Identify best model\n",
    "if sorted_results:\n",
    "    best_model_name = sorted_results[0][0]\n",
    "    best_score = sorted_results[0][1]['test_r2']\n",
    "    best_mae = sorted_results[0][1]['test_mae']\n",
    "    \n",
    "    print(f\"\\n🏆 Best Linear Model: {best_model_name}\")\n",
    "    print(f\"   CV R² = {best_score:.4f} (±{sorted_results[0][1]['test_r2_std']:.4f})\")\n",
    "    print(f\"   CV MAE = {best_mae:.2f} wins (±{sorted_results[0][1]['test_mae_std']:.2f})\")\n",
    "\n",
    "# Feature importance for best linear model\n",
    "print(f\"\\n📊 FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Training {best_model_name} on full dataset for feature importance...\")\n",
    "\n",
    "# Get the best model and train it on full data\n",
    "best_linear_model = models_linear[best_model_name]\n",
    "best_linear_model.fit(X_linear, y)\n",
    "\n",
    "# Handle different model types for feature importance\n",
    "if 'Polynomial' in best_model_name:\n",
    "    # For polynomial features, we need to get feature names from the pipeline\n",
    "    print(\"⚠️  Note: Polynomial Ridge creates many interaction features\")\n",
    "    print(\"    Showing top 15 coefficients (may include feature interactions)\")\n",
    "    \n",
    "    # Get the polynomial feature transformer\n",
    "    poly_transformer = best_linear_model.named_steps['poly']\n",
    "    feature_names_poly = poly_transformer.get_feature_names_out(X_linear.columns)\n",
    "    \n",
    "    # Get coefficients from the final model\n",
    "    coefficients = best_linear_model.named_steps['model'].coef_\n",
    "    \n",
    "    # Create feature importance DataFrame\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names_poly,\n",
    "        'coefficient': coefficients,\n",
    "        'abs_coefficient': np.abs(coefficients)\n",
    "    }).sort_values('abs_coefficient', ascending=False)\n",
    "    \n",
    "else:\n",
    "    # For regular linear models, use original feature names\n",
    "    coefficients = best_linear_model.named_steps['model'].coef_\n",
    "    \n",
    "    # Create feature importance DataFrame using absolute coefficients\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': X_linear.columns,\n",
    "        'coefficient': coefficients,\n",
    "        'abs_coefficient': np.abs(coefficients)\n",
    "    }).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 15 Most Important Features ({best_model_name}):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Feature':<25} {'Coefficient':<15} {'Abs Value':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, row in feature_importance_df.head(15).iterrows():\n",
    "    coef_sign = \"+\" if row['coefficient'] >= 0 else \"\"\n",
    "    print(f\"{row['feature']:<25} {coef_sign}{row['coefficient']:<14.4f} {row['abs_coefficient']:<12.4f}\")\n",
    "\n",
    "# Additional insights\n",
    "print(f\"\\nFeature Importance Insights:\")\n",
    "print(f\"• Positive coefficients increase wins\")\n",
    "print(f\"• Negative coefficients decrease wins\") \n",
    "print(f\"• Larger absolute values = stronger influence\")\n",
    "\n",
    "# Count positive vs negative coefficients in top 15\n",
    "top15_coeffs = feature_importance_df.head(15)['coefficient']\n",
    "positive_count = (top15_coeffs > 0).sum()\n",
    "negative_count = (top15_coeffs < 0).sum()\n",
    "print(f\"• Top 15 features: {positive_count} positive, {negative_count} negative coefficients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc4f5b",
   "metadata": {},
   "source": [
    "# Phase 1: Weighted Ensemble Implementation\n",
    "\n",
    "Based on your individual model results, we'll now implement a weighted ensemble approach to combine the best performing models. This should help us break below the 3.0 MAE barrier by leveraging the strengths of different model types.\n",
    "\n",
    "## Strategy:\n",
    "- Select top performing models from both linear and boosting categories\n",
    "- Use cross-validation performance to determine optimal weights\n",
    "- Weight linear regression higher since it performed best on Kaggle (3.05136)\n",
    "- Generate ensemble predictions for final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9bb6133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1: WEIGHTED ENSEMBLE IMPLEMENTATION\n",
      "============================================================\n",
      "\n",
      "1. SELECTING TOP MODELS\n",
      "----------------------------------------\n",
      "Top Linear Models (by CV R²):\n",
      "  Lasso (alpha=0.01): R² = 0.9312, MAE = 2.72\n",
      "  Ridge (alpha=10): R² = 0.9308, MAE = 2.73\n",
      "  Ridge (alpha=1.0): R² = 0.9308, MAE = 2.73\n",
      "\n",
      "Top Boosting Models (by CV R²):\n",
      "  CatBoost: R² = 0.9120, MAE = 3.07\n",
      "  XGBoost: R² = 0.9081, MAE = 3.16\n",
      "\n",
      "2. ENSEMBLE COMPOSITION\n",
      "----------------------------------------\n",
      "Selected 3 models for ensemble:\n",
      "  ✓ Lasso (alpha=0.01)\n",
      "  ✓ Ridge (alpha=10)\n",
      "  ✓ CatBoost\n",
      "\n",
      "Total ensemble models: 3\n",
      "\n",
      "3. MODEL PERFORMANCE SUMMARY\n",
      "----------------------------------------\n",
      "Lasso (alpha=0.01): MAE = 2.72, R² = 0.9312\n",
      "Ridge (alpha=10): MAE = 2.73, R² = 0.9308\n",
      "CatBoost: MAE = 3.07, R² = 0.9120\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 1: WEIGHTED ENSEMBLE IMPLEMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# First, let's identify our top performing models from both categories\n",
    "print(\"\\n1. SELECTING TOP MODELS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Top 3 linear models (based on CV R²)\n",
    "top_linear_models = dict(sorted(successful_results.items(), key=lambda x: x[1]['test_r2'], reverse=True)[:3])\n",
    "print(\"Top Linear Models (by CV R²):\")\n",
    "for name, result in top_linear_models.items():\n",
    "    print(f\"  {name}: R² = {result['test_r2']:.4f}, MAE = {result['test_mae']:.2f}\")\n",
    "\n",
    "# Top 2 boosting models (from previous results)\n",
    "top_boosting_models = dict(sorted(cv_results.items(), key=lambda x: x[1]['test_r2'], reverse=True)[:2])\n",
    "print(\"\\nTop Boosting Models (by CV R²):\")\n",
    "for name, result in top_boosting_models.items():\n",
    "    print(f\"  {name}: R² = {result['test_r2']:.4f}, MAE = {result['test_mae']:.2f}\")\n",
    "\n",
    "# Select our ensemble candidates (top performers from each category)\n",
    "ensemble_models = {}\n",
    "\n",
    "# Add top 2 linear models\n",
    "linear_names = list(top_linear_models.keys())[:2]\n",
    "for name in linear_names:\n",
    "    ensemble_models[name] = models_linear[name]\n",
    "\n",
    "# Add top 1 boosting model\n",
    "boosting_name = list(top_boosting_models.keys())[0]\n",
    "ensemble_models[boosting_name] = models[boosting_name]\n",
    "\n",
    "print(f\"\\n2. ENSEMBLE COMPOSITION\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Selected {len(ensemble_models)} models for ensemble:\")\n",
    "for name in ensemble_models.keys():\n",
    "    print(f\"  ✓ {name}\")\n",
    "    \n",
    "print(f\"\\nTotal ensemble models: {len(ensemble_models)}\")\n",
    "\n",
    "# Store performance metrics for weight calculation\n",
    "model_performance = {}\n",
    "for name in ensemble_models.keys():\n",
    "    if name in successful_results:  # Linear model\n",
    "        model_performance[name] = {\n",
    "            'mae': successful_results[name]['test_mae'],\n",
    "            'r2': successful_results[name]['test_r2']\n",
    "        }\n",
    "    else:  # Boosting model\n",
    "        model_performance[name] = {\n",
    "            'mae': cv_results[name]['test_mae'], \n",
    "            'r2': cv_results[name]['test_r2']\n",
    "        }\n",
    "\n",
    "print(f\"\\n3. MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "for name, perf in model_performance.items():\n",
    "    print(f\"{name}: MAE = {perf['mae']:.2f}, R² = {perf['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e9e2121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. GENERATING OUT-OF-FOLD PREDICTIONS\n",
      "----------------------------------------\n",
      "Generating OOF predictions for Lasso (alpha=0.01)...\n",
      "  OOF MAE: 2.723\n",
      "Generating OOF predictions for Ridge (alpha=10)...\n",
      "  OOF MAE: 2.730\n",
      "Generating OOF predictions for CatBoost...\n",
      "  OOF MAE: 2.723\n",
      "Generating OOF predictions for Ridge (alpha=10)...\n",
      "  OOF MAE: 2.730\n",
      "Generating OOF predictions for CatBoost...\n",
      "  OOF MAE: 3.093\n",
      "\n",
      "OOF prediction matrix shape: (1812, 3)\n",
      "\n",
      "5. OPTIMIZING ENSEMBLE WEIGHTS\n",
      "----------------------------------------\n",
      "Initial weights (based on inverse MAE):\n",
      "  Lasso (alpha=0.01): 0.347\n",
      "  Ridge (alpha=10): 0.346\n",
      "  CatBoost: 0.307\n",
      "\n",
      "Optimization successful: True\n",
      "Optimal ensemble OOF MAE: 2.7231\n",
      "\n",
      "Optimal weights:\n",
      "  Lasso (alpha=0.01): 0.952\n",
      "  Ridge (alpha=10): 0.014\n",
      "  CatBoost: 0.033\n",
      "\n",
      "Improvement over best individual model:\n",
      "  Best individual MAE: 2.7234\n",
      "  Ensemble MAE: 2.7231\n",
      "  Improvement: 0.0002 (0.01%)\n",
      "  OOF MAE: 3.093\n",
      "\n",
      "OOF prediction matrix shape: (1812, 3)\n",
      "\n",
      "5. OPTIMIZING ENSEMBLE WEIGHTS\n",
      "----------------------------------------\n",
      "Initial weights (based on inverse MAE):\n",
      "  Lasso (alpha=0.01): 0.347\n",
      "  Ridge (alpha=10): 0.346\n",
      "  CatBoost: 0.307\n",
      "\n",
      "Optimization successful: True\n",
      "Optimal ensemble OOF MAE: 2.7231\n",
      "\n",
      "Optimal weights:\n",
      "  Lasso (alpha=0.01): 0.952\n",
      "  Ridge (alpha=10): 0.014\n",
      "  CatBoost: 0.033\n",
      "\n",
      "Improvement over best individual model:\n",
      "  Best individual MAE: 2.7234\n",
      "  Ensemble MAE: 2.7231\n",
      "  Improvement: 0.0002 (0.01%)\n"
     ]
    }
   ],
   "source": [
    "# Generate out-of-fold predictions for weight optimization\n",
    "print(\"\\n4. GENERATING OUT-OF-FOLD PREDICTIONS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Generate OOF predictions for each model\n",
    "oof_predictions = {}\n",
    "model_names = list(ensemble_models.keys())\n",
    "\n",
    "for name, model in ensemble_models.items():\n",
    "    print(f\"Generating OOF predictions for {name}...\")\n",
    "    \n",
    "    # Use the same CV strategy as before\n",
    "    oof_pred = cross_val_predict(model, X_full, y_full, cv=cv, method='predict')\n",
    "    oof_predictions[name] = oof_pred\n",
    "    \n",
    "    # Calculate OOF MAE\n",
    "    oof_mae = mean_absolute_error(y_full, oof_pred)\n",
    "    print(f\"  OOF MAE: {oof_mae:.3f}\")\n",
    "\n",
    "# Create OOF prediction matrix\n",
    "oof_matrix = np.column_stack([oof_predictions[name] for name in model_names])\n",
    "print(f\"\\nOOF prediction matrix shape: {oof_matrix.shape}\")\n",
    "\n",
    "print(\"\\n5. OPTIMIZING ENSEMBLE WEIGHTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def ensemble_mae_objective(weights, predictions, targets):\n",
    "    \"\"\"Objective function to minimize: weighted ensemble MAE\"\"\"\n",
    "    weights = np.array(weights)\n",
    "    weights = weights / weights.sum()  # Normalize to sum to 1\n",
    "    ensemble_pred = np.dot(predictions, weights)\n",
    "    return mean_absolute_error(targets, ensemble_pred)\n",
    "\n",
    "# Initial weights based on inverse MAE (better models get higher weights)\n",
    "initial_weights = []\n",
    "for name in model_names:\n",
    "    mae = model_performance[name]['mae']\n",
    "    # Inverse weight: lower MAE = higher weight\n",
    "    weight = 1.0 / mae if mae > 0 else 1.0\n",
    "    initial_weights.append(weight)\n",
    "\n",
    "# Normalize initial weights\n",
    "initial_weights = np.array(initial_weights)\n",
    "initial_weights = initial_weights / initial_weights.sum()\n",
    "\n",
    "print(\"Initial weights (based on inverse MAE):\")\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f\"  {name}: {initial_weights[i]:.3f}\")\n",
    "\n",
    "# Constraint: weights must sum to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0})\n",
    "\n",
    "# Bounds: each weight between 0 and 1\n",
    "bounds = [(0.0, 1.0) for _ in range(len(model_names))]\n",
    "\n",
    "# Optimize weights\n",
    "result = minimize(\n",
    "    ensemble_mae_objective,\n",
    "    initial_weights,\n",
    "    args=(oof_matrix, y_full),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "optimal_weights = result.x\n",
    "optimal_mae = result.fun\n",
    "\n",
    "print(f\"\\nOptimization successful: {result.success}\")\n",
    "print(f\"Optimal ensemble OOF MAE: {optimal_mae:.4f}\")\n",
    "print(\"\\nOptimal weights:\")\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f\"  {name}: {optimal_weights[i]:.3f}\")\n",
    "\n",
    "# Calculate improvement over best individual model\n",
    "best_individual_mae = min([model_performance[name]['mae'] for name in model_names])\n",
    "improvement = best_individual_mae - optimal_mae\n",
    "print(f\"\\nImprovement over best individual model:\")\n",
    "print(f\"  Best individual MAE: {best_individual_mae:.4f}\")\n",
    "print(f\"  Ensemble MAE: {optimal_mae:.4f}\")\n",
    "print(f\"  Improvement: {improvement:.4f} ({improvement/best_individual_mae*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5ad7aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. TRAINING FINAL ENSEMBLE MODELS\n",
      "----------------------------------------\n",
      "Training Lasso (alpha=0.01) on full dataset...\n",
      "  Test predictions range: 44.85 to 109.52\n",
      "Training Ridge (alpha=10) on full dataset...\n",
      "  Test predictions range: 44.55 to 109.03\n",
      "Training CatBoost on full dataset...\n",
      "  Test predictions range: 47.82 to 101.78\n",
      "\n",
      "All 3 models trained successfully!\n",
      "Test prediction matrix shape: (453, 3)\n",
      "\n",
      "7. GENERATING ENSEMBLE PREDICTIONS\n",
      "----------------------------------------\n",
      "Ensemble test predictions:\n",
      "  Range: 44.95 to 109.25\n",
      "  Mean: 79.08\n",
      "  Std: 12.03\n",
      "\n",
      "Comparison with individual models:\n",
      "  Lasso (alpha=0.01) (weight=0.952): mean=79.08, std=12.05\n",
      "  Ridge (alpha=10) (weight=0.014): mean=79.11, std=12.01\n",
      "  CatBoost (weight=0.033): mean=79.07, std=11.77\n",
      "\n",
      "8. CREATING SUBMISSION FILE\n",
      "----------------------------------------\n",
      "✅ Submission saved: submission_weighted_ensemble_20251004_170139.csv\n",
      "📁 Path: /home/chrisfkh/sctp-ds-ai/mod3/kaggle_moneyball/submissions/submission_weighted_ensemble_20251004_170139.csv\n",
      "📊 Predictions shape: (453, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "     ID          W\n",
      "0  1756  69.340842\n",
      "1  1282  74.379477\n",
      "2   351  84.288222\n",
      "3   421  87.145467\n",
      "4    57  93.312084\n",
      "5  1557  97.513117\n",
      "6   846  79.226106\n",
      "7  1658  84.154895\n",
      "8   112  72.942946\n",
      "9  2075  83.639619\n",
      "\n",
      "9. ENSEMBLE SUMMARY\n",
      "----------------------------------------\n",
      "Ensemble Composition:\n",
      "  Lasso (alpha=0.01): 95.2%\n",
      "  Ridge (alpha=10): 1.4%\n",
      "  CatBoost: 3.3%\n",
      "\n",
      "Expected Performance:\n",
      "  Cross-validation MAE: 2.7231\n",
      "  Expected Kaggle score: ~2.72\n",
      "  Improvement vs best individual: 0.0002\n",
      "  Test predictions range: 47.82 to 101.78\n",
      "\n",
      "All 3 models trained successfully!\n",
      "Test prediction matrix shape: (453, 3)\n",
      "\n",
      "7. GENERATING ENSEMBLE PREDICTIONS\n",
      "----------------------------------------\n",
      "Ensemble test predictions:\n",
      "  Range: 44.95 to 109.25\n",
      "  Mean: 79.08\n",
      "  Std: 12.03\n",
      "\n",
      "Comparison with individual models:\n",
      "  Lasso (alpha=0.01) (weight=0.952): mean=79.08, std=12.05\n",
      "  Ridge (alpha=10) (weight=0.014): mean=79.11, std=12.01\n",
      "  CatBoost (weight=0.033): mean=79.07, std=11.77\n",
      "\n",
      "8. CREATING SUBMISSION FILE\n",
      "----------------------------------------\n",
      "✅ Submission saved: submission_weighted_ensemble_20251004_170139.csv\n",
      "📁 Path: /home/chrisfkh/sctp-ds-ai/mod3/kaggle_moneyball/submissions/submission_weighted_ensemble_20251004_170139.csv\n",
      "📊 Predictions shape: (453, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "     ID          W\n",
      "0  1756  69.340842\n",
      "1  1282  74.379477\n",
      "2   351  84.288222\n",
      "3   421  87.145467\n",
      "4    57  93.312084\n",
      "5  1557  97.513117\n",
      "6   846  79.226106\n",
      "7  1658  84.154895\n",
      "8   112  72.942946\n",
      "9  2075  83.639619\n",
      "\n",
      "9. ENSEMBLE SUMMARY\n",
      "----------------------------------------\n",
      "Ensemble Composition:\n",
      "  Lasso (alpha=0.01): 95.2%\n",
      "  Ridge (alpha=10): 1.4%\n",
      "  CatBoost: 3.3%\n",
      "\n",
      "Expected Performance:\n",
      "  Cross-validation MAE: 2.7231\n",
      "  Expected Kaggle score: ~2.72\n",
      "  Improvement vs best individual: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Train final models and generate test predictions\n",
    "print(\"\\n6. TRAINING FINAL ENSEMBLE MODELS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Train each model on the full training dataset\n",
    "final_models = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for name, model in ensemble_models.items():\n",
    "    print(f\"Training {name} on full dataset...\")\n",
    "    \n",
    "    # Clone and train the model\n",
    "    final_model = model  # Pipeline already configured\n",
    "    final_model.fit(X_full, y_full)\n",
    "    final_models[name] = final_model\n",
    "    \n",
    "    # Generate test predictions\n",
    "    test_pred = final_model.predict(X_test_final)\n",
    "    test_predictions[name] = test_pred\n",
    "    \n",
    "    print(f\"  Test predictions range: {test_pred.min():.2f} to {test_pred.max():.2f}\")\n",
    "\n",
    "print(f\"\\nAll {len(final_models)} models trained successfully!\")\n",
    "\n",
    "# Create test prediction matrix\n",
    "test_matrix = np.column_stack([test_predictions[name] for name in model_names])\n",
    "print(f\"Test prediction matrix shape: {test_matrix.shape}\")\n",
    "\n",
    "print(\"\\n7. GENERATING ENSEMBLE PREDICTIONS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Generate weighted ensemble predictions\n",
    "ensemble_test_pred = np.dot(test_matrix, optimal_weights)\n",
    "\n",
    "print(f\"Ensemble test predictions:\")\n",
    "print(f\"  Range: {ensemble_test_pred.min():.2f} to {ensemble_test_pred.max():.2f}\")\n",
    "print(f\"  Mean: {ensemble_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {ensemble_test_pred.std():.2f}\")\n",
    "\n",
    "# Compare with individual model predictions\n",
    "print(f\"\\nComparison with individual models:\")\n",
    "for i, name in enumerate(model_names):\n",
    "    individual_pred = test_predictions[name]\n",
    "    weight = optimal_weights[i]\n",
    "    print(f\"  {name} (weight={weight:.3f}): mean={individual_pred.mean():.2f}, std={individual_pred.std():.2f}\")\n",
    "\n",
    "print(f\"\\n8. CREATING SUBMISSION FILE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': test_df['ID'],  # Use the actual ID column from test.csv\n",
    "    'W': ensemble_test_pred\n",
    "})\n",
    "\n",
    "# Generate timestamp for unique filename\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "submission_filename = f\"submission_weighted_ensemble_{timestamp}.csv\"\n",
    "submission_path = SUB_DIR / submission_filename\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"✅ Submission saved: {submission_filename}\")\n",
    "print(f\"📁 Path: {submission_path}\")\n",
    "print(f\"📊 Predictions shape: {submission_df.shape}\")\n",
    "\n",
    "# Display first few predictions\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(f\"\\n9. ENSEMBLE SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Ensemble Composition:\")\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f\"  {name}: {optimal_weights[i]:.1%}\")\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  Cross-validation MAE: {optimal_mae:.4f}\")\n",
    "print(f\"  Expected Kaggle score: ~{optimal_mae:.2f}\")\n",
    "print(f\"  Improvement vs best individual: {improvement:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889453b4",
   "metadata": {},
   "source": [
    "# Stacked Ensemble Implementation\n",
    "\n",
    "The weighted ensemble scored 3.04775 on Kaggle vs 2.7190 CV, indicating distribution mismatch between CV and test set. \n",
    "\n",
    "## Stacking Strategy:\n",
    "- **Expand base models**: Include more diverse models (XGBoost, LightGBM, different regularization strengths)\n",
    "- **Two-level stacking**: Level 1 base models → Level 2 meta-learner \n",
    "- **Robust meta-learner**: Use Ridge regression to combine predictions and learn complex relationships\n",
    "- **Better generalization**: Out-of-fold training prevents overfitting to specific data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dc6aaa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STACKED ENSEMBLE IMPLEMENTATION\n",
      "==================================================\n",
      "\n",
      "1. EXPANDING BASE MODEL DIVERSITY\n",
      "----------------------------------------\n",
      "Base models for stacking: 8\n",
      "  ✓ Ridge_weak\n",
      "  ✓ Ridge_strong\n",
      "  ✓ Lasso_weak\n",
      "  ✓ Lasso_strong\n",
      "  ✓ ElasticNet\n",
      "  ✓ XGBoost_conservative\n",
      "  ✓ LightGBM_conservative\n",
      "  ✓ CatBoost_conservative\n",
      "\n",
      "2. IMPLEMENTING STACKED ENSEMBLE\n",
      "----------------------------------------\n",
      "Generating Level 1 out-of-fold predictions...\n",
      "  Processing Ridge_weak...\n",
      "    OOF MAE: 2.7347\n",
      "  Processing Ridge_strong...\n",
      "    OOF MAE: 2.7302\n",
      "  Processing Lasso_weak...\n",
      "    OOF MAE: 2.7234\n",
      "  Processing Lasso_strong...\n",
      "    OOF MAE: 2.8830\n",
      "  Processing ElasticNet...\n",
      "    OOF MAE: 2.8773\n",
      "  Processing XGBoost_conservative...\n",
      "    OOF MAE: 2.7234\n",
      "  Processing Lasso_strong...\n",
      "    OOF MAE: 2.8830\n",
      "  Processing ElasticNet...\n",
      "    OOF MAE: 2.8773\n",
      "  Processing XGBoost_conservative...\n",
      "    OOF MAE: 3.1026\n",
      "  Processing LightGBM_conservative...\n",
      "    OOF MAE: 3.0608\n",
      "  Processing CatBoost_conservative...\n",
      "    OOF MAE: 3.1026\n",
      "  Processing LightGBM_conservative...\n",
      "    OOF MAE: 3.0608\n",
      "  Processing CatBoost_conservative...\n",
      "    OOF MAE: 3.0458\n",
      "\n",
      "Level 1 OOF predictions shape: (1812, 8)\n",
      "Level 1 test predictions shape: (453, 8)\n",
      "    OOF MAE: 3.0458\n",
      "\n",
      "Level 1 OOF predictions shape: (1812, 8)\n",
      "Level 1 test predictions shape: (453, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"STACKED ENSEMBLE IMPLEMENTATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"\\n1. EXPANDING BASE MODEL DIVERSITY\") \n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create more diverse base models for better generalization\n",
    "stacking_models = {\n",
    "    # Linear models with different regularization strengths\n",
    "    'Ridge_weak': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=0.1))  # Less regularization\n",
    "    ]),\n",
    "    \n",
    "    'Ridge_strong': Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('model', Ridge(alpha=10.0))  # More regularization\n",
    "    ]),\n",
    "    \n",
    "    'Lasso_weak': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(alpha=0.01, max_iter=5000))\n",
    "    ]),\n",
    "    \n",
    "    'Lasso_strong': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(alpha=0.1, max_iter=5000))\n",
    "    ]),\n",
    "    \n",
    "    'ElasticNet': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=5000))\n",
    "    ]),\n",
    "    \n",
    "    # Tree-based models\n",
    "    'XGBoost_conservative': XGBRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=4,  # Shallower for better generalization\n",
    "        learning_rate=0.08,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    \n",
    "    'LightGBM_conservative': LGBMRegressor(\n",
    "        n_estimators=150,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.08,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    \n",
    "    'CatBoost_conservative': CatBoostRegressor(\n",
    "        iterations=150,\n",
    "        depth=4,\n",
    "        learning_rate=0.08,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"Base models for stacking: {len(stacking_models)}\")\n",
    "for name in stacking_models.keys():\n",
    "    print(f\"  ✓ {name}\")\n",
    "\n",
    "print(f\"\\n2. IMPLEMENTING STACKED ENSEMBLE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Use the same CV folds for all models to ensure consistency  \n",
    "stacking_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Level 1: Generate out-of-fold predictions from base models\n",
    "print(\"Generating Level 1 out-of-fold predictions...\")\n",
    "\n",
    "level1_oof_preds = np.zeros((len(X_full), len(stacking_models)))\n",
    "level1_test_preds = np.zeros((len(X_test_final), len(stacking_models)))\n",
    "\n",
    "model_names_stack = list(stacking_models.keys())\n",
    "\n",
    "for i, (name, model) in enumerate(stacking_models.items()):\n",
    "    print(f\"  Processing {name}...\")\n",
    "    \n",
    "    # Generate OOF predictions\n",
    "    oof_pred = cross_val_predict(model, X_full, y_full, cv=stacking_cv, method='predict')\n",
    "    level1_oof_preds[:, i] = oof_pred\n",
    "    \n",
    "    # Train on full dataset and predict test set\n",
    "    model_clone = clone(model)\n",
    "    model_clone.fit(X_full, y_full)\n",
    "    test_pred = model_clone.predict(X_test_final)\n",
    "    level1_test_preds[:, i] = test_pred\n",
    "    \n",
    "    # Calculate individual model OOF MAE\n",
    "    oof_mae = mean_absolute_error(y_full, oof_pred)\n",
    "    print(f\"    OOF MAE: {oof_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nLevel 1 OOF predictions shape: {level1_oof_preds.shape}\")\n",
    "print(f\"Level 1 test predictions shape: {level1_test_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "54168822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. TRAINING LEVEL 2 META-LEARNER\n",
      "----------------------------------------\n",
      "Evaluating meta-learners:\n",
      "  Ridge_meta_weak: MAE = 2.7300 (±0.0549)\n",
      "  Ridge_meta_medium: MAE = 2.7299 (±0.0546)\n",
      "  Ridge_meta_strong: MAE = 2.7293 (±0.0523)\n",
      "  Lasso_meta: MAE = 2.7305 (±0.0480)\n",
      "  ElasticNet_meta: MAE = 2.7313 (±0.0491)\n",
      "\n",
      "Best meta-learner: Ridge_meta_strong\n",
      "Best meta-learner CV MAE: 2.7293\n",
      "\n",
      "4. TRAINING FINAL STACKED MODEL\n",
      "----------------------------------------\n",
      "Stacked ensemble test predictions:\n",
      "  Range: 45.03 to 109.12\n",
      "  Mean: 79.04\n",
      "  Std: 12.08\n",
      "\n",
      "5. COMPARISON WITH PHASE 1\n",
      "----------------------------------------\n",
      "Phase 1 ensemble predictions:\n",
      "  Range: 44.95 to 109.25\n",
      "  Mean: 79.08\n",
      "  Std: 12.03\n",
      "\n",
      "Phase 2 stacked predictions:\n",
      "  Range: 45.03 to 109.12\n",
      "  Mean: 79.04\n",
      "  Std: 12.08\n",
      "\n",
      "Correlation between Phase 1 and Phase 2: 0.9999\n",
      "\n",
      "Phase 2 (stacked ensemble):\n",
      "  CV MAE: 2.7293\n",
      "  Expected improvement vs Phase 1: -0.0062\n",
      "  ⚠️  Phase 2 CV did not improve Phase 1\n"
     ]
    }
   ],
   "source": [
    "# Level 2: Train meta-learner\n",
    "print(f\"\\n3. TRAINING LEVEL 2 META-LEARNER\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Import the missing function\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Try multiple meta-learners to find the best one\n",
    "meta_learners = {\n",
    "    'Ridge_meta_weak': Ridge(alpha=0.1),\n",
    "    'Ridge_meta_medium': Ridge(alpha=1.0), \n",
    "    'Ridge_meta_strong': Ridge(alpha=10.0),\n",
    "    'Lasso_meta': Lasso(alpha=0.01, max_iter=5000),\n",
    "    'ElasticNet_meta': ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=5000)\n",
    "}\n",
    "\n",
    "best_meta_mae = float('inf')\n",
    "best_meta_name = None\n",
    "best_meta_model = None\n",
    "\n",
    "print(\"Evaluating meta-learners:\")\n",
    "for name, meta_model in meta_learners.items():\n",
    "    # Cross-validate the meta-learner on OOF predictions\n",
    "    meta_cv_scores = cross_val_score(\n",
    "        meta_model, level1_oof_preds, y_full,\n",
    "        cv=5, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "    meta_mae = -meta_cv_scores.mean()\n",
    "    meta_mae_std = meta_cv_scores.std()\n",
    "    \n",
    "    print(f\"  {name}: MAE = {meta_mae:.4f} (±{meta_mae_std:.4f})\")\n",
    "    \n",
    "    if meta_mae < best_meta_mae:\n",
    "        best_meta_mae = meta_mae\n",
    "        best_meta_name = name\n",
    "        best_meta_model = meta_model\n",
    "\n",
    "print(f\"\\nBest meta-learner: {best_meta_name}\")\n",
    "print(f\"Best meta-learner CV MAE: {best_meta_mae:.4f}\")\n",
    "\n",
    "# Train the best meta-learner on all OOF predictions\n",
    "print(f\"\\n4. TRAINING FINAL STACKED MODEL\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "final_meta_model = clone(best_meta_model)\n",
    "final_meta_model.fit(level1_oof_preds, y_full)\n",
    "\n",
    "# Generate final stacked predictions\n",
    "stacked_test_pred = final_meta_model.predict(level1_test_preds)\n",
    "\n",
    "print(f\"Stacked ensemble test predictions:\")\n",
    "print(f\"  Range: {stacked_test_pred.min():.2f} to {stacked_test_pred.max():.2f}\")\n",
    "print(f\"  Mean: {stacked_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {stacked_test_pred.std():.2f}\")\n",
    "\n",
    "# Compare with Phase 1 ensemble\n",
    "print(f\"\\n5. COMPARISON WITH PHASE 1\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Phase 1 ensemble predictions:\")\n",
    "print(f\"  Range: {ensemble_test_pred.min():.2f} to {ensemble_test_pred.max():.2f}\")\n",
    "print(f\"  Mean: {ensemble_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {ensemble_test_pred.std():.2f}\")\n",
    "\n",
    "print(f\"\\nPhase 2 stacked predictions:\")\n",
    "print(f\"  Range: {stacked_test_pred.min():.2f} to {stacked_test_pred.max():.2f}\")  \n",
    "print(f\"  Mean: {stacked_test_pred.mean():.2f}\")\n",
    "print(f\"  Std: {stacked_test_pred.std():.2f}\")\n",
    "\n",
    "# Calculate correlation between Phase 1 and Phase 2 predictions\n",
    "correlation = np.corrcoef(ensemble_test_pred, stacked_test_pred)[0, 1]\n",
    "print(f\"\\nCorrelation between Phase 1 and Phase 2: {correlation:.4f}\")\n",
    "\n",
    "print(f\"\\nPhase 2 (stacked ensemble):\")\n",
    "print(f\"  CV MAE: {best_meta_mae:.4f}\")\n",
    "improvement_vs_phase1 = optimal_mae - best_meta_mae\n",
    "print(f\"  Expected improvement vs Phase 1: {improvement_vs_phase1:.4f}\")\n",
    "\n",
    "if best_meta_mae < optimal_mae:\n",
    "    print(f\"  ✅ Phase 2 shows improvement over Phase 1!\")\n",
    "else:\n",
    "    print(f\"  ⚠️  Phase 2 CV did not improve Phase 1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0cb2464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. CREATING STACKED ENSEMBLE SUBMISSION\n",
      "----------------------------------------\n",
      "✅ Stacked ensemble submission saved: submission_stacked_ensemble_20251004_170141.csv\n",
      "📁 Path: /home/chrisfkh/sctp-ds-ai/mod3/kaggle_moneyball/submissions/submission_stacked_ensemble_20251004_170141.csv\n",
      "📊 Predictions shape: (453, 2)\n",
      "\n",
      "First 10 predictions:\n",
      "     ID          W\n",
      "0  1756  69.210882\n",
      "1  1282  74.421222\n",
      "2   351  84.214536\n",
      "3   421  87.177143\n",
      "4    57  93.234779\n",
      "5  1557  97.552946\n",
      "6   846  79.052509\n",
      "7  1658  83.860262\n",
      "8   112  73.189547\n",
      "9  2075  83.637957\n",
      "\n",
      "8. STACKED ENSEMBLE SUMMARY\n",
      "----------------------------------------\n",
      "Base Models: 8\n",
      "  • Ridge_weak\n",
      "  • Ridge_strong\n",
      "  • Lasso_weak\n",
      "  • Lasso_strong\n",
      "  • ElasticNet\n",
      "  • XGBoost_conservative\n",
      "  • LightGBM_conservative\n",
      "  • CatBoost_conservative\n",
      "\n",
      "Meta-learner: Ridge_meta_strong\n",
      "Expected CV MAE: 2.7293\n"
     ]
    }
   ],
   "source": [
    "# Create stacked ensemble submission\n",
    "print(f\"\\n7. CREATING STACKED ENSEMBLE SUBMISSION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create submission DataFrame for stacked ensemble\n",
    "stacked_submission_df = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'W': stacked_test_pred\n",
    "})\n",
    "\n",
    "# Generate timestamp\n",
    "timestamp_stacked = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "stacked_submission_filename = f\"submission_stacked_ensemble_{timestamp_stacked}.csv\"\n",
    "stacked_submission_path = SUB_DIR / stacked_submission_filename\n",
    "\n",
    "# Save submission\n",
    "stacked_submission_df.to_csv(stacked_submission_path, index=False)\n",
    "\n",
    "print(f\"✅ Stacked ensemble submission saved: {stacked_submission_filename}\")\n",
    "print(f\"📁 Path: {stacked_submission_path}\")\n",
    "print(f\"📊 Predictions shape: {stacked_submission_df.shape}\")\n",
    "\n",
    "# Display first few predictions\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(stacked_submission_df.head(10))\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n8. STACKED ENSEMBLE SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Base Models: {len(stacking_models)}\")\n",
    "for name in model_names_stack:\n",
    "    print(f\"  • {name}\")\n",
    "\n",
    "print(f\"\\nMeta-learner: {best_meta_name}\")\n",
    "print(f\"Expected CV MAE: {best_meta_mae:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
